name: üöÄ Complete June Services CI/CD Pipeline (Fixed)

on:
  push:
    branches: [ main, develop ]
    paths-ignore: [ 'README.md', 'docs/**', '.gitignore' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Image tag to deploy'
        required: true
        default: 'latest'
        type: string
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options: 
          - production
          - staging
          - development
      services:
        description: 'Services to deploy (comma-separated, empty for all)'
        required: false
        default: ''
        type: string
      force_restart:
        description: 'Force restart deployments'
        required: false
        default: false
        type: boolean
      build_images:
        description: 'Build and push Docker images'
        required: false
        default: true
        type: boolean
      promote_to_production_cert:
        description: '‚ö†Ô∏è Promote staging cert to production (ONLY after staging works!)'
        required: false
        default: false
        type: boolean

env:
  REGISTRY: docker.io/${{ secrets.DOCKERHUB_USERNAME }}
  KUBE_NAMESPACE: june-services
  IMAGE_TAG: ${{ github.event.inputs.image_tag || github.sha }}

permissions:
  contents: read
  packages: write

jobs:
  build-and-push:
    name: üî® Build & Push Images
    runs-on: self-hosted
    if: github.event.inputs.build_images != 'false'
    strategy:
      fail-fast: false
      matrix:
        service: [june-stt, june-tts, june-orchestrator, june-idp, june-web, june-dark]
    steps:
      - name: üì¶ Checkout repository
        uses: actions/checkout@v4

      - name: üîê Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: üîß Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üìù Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=sha-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=${{ env.IMAGE_TAG }}

      - name: üèóÔ∏è Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.service }}
          file: ./${{ matrix.service }}/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

  deploy:
    name: üöÄ Deploy to K8s
    runs-on: self-hosted
    needs: build-and-push
    if: always() && (needs.build-and-push.result == 'success' || needs.build-and-push.result == 'skipped')

    steps:
      - name: üì¶ Checkout repository
        uses: actions/checkout@v4

      - name: üîç Verify k8s manifest files
        run: |
          set -e
          echo "üîç Verifying k8s manifest files..."
          ls -la k8s || true
          test -f k8s/namespace.yaml || echo "‚ö†Ô∏è k8s/namespace.yaml not found"

      - name: üîç Verify Kubernetes connection
        run: |
          echo "üîç Testing Kubernetes connection..."
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: üéÆ Configure GPU Support
        run: |
          echo "üéÆ Configuring GPU node labels and checking GPU Operator..."
          
          echo "üè∑Ô∏è  Labeling nodes for GPU workloads..."
          for node in $(kubectl get nodes -o name); do
            kubectl label $node gpu=true --overwrite
            echo "‚úÖ Labeled: $node"
          done
          
          echo ""
          echo "üîç Checking GPU Operator status..."
          if kubectl get namespace gpu-operator &>/dev/null; then
            echo "‚úÖ GPU Operator namespace exists"
            echo "üìä GPU Operator pods:"
            kubectl get pods -n gpu-operator
            
            echo ""
            echo "‚è≥ Waiting for GPU Operator components..."
            
            if kubectl get daemonset -n gpu-operator nvidia-device-plugin-daemonset &>/dev/null; then
              echo "‚è≥ Waiting for device plugin..."
              kubectl rollout status daemonset/nvidia-device-plugin-daemonset -n gpu-operator --timeout=300s || {
                echo "‚ö†Ô∏è Device plugin taking longer than expected"
              }
            fi
            
            if kubectl get daemonset -n gpu-operator nvidia-container-toolkit-daemonset &>/dev/null; then
              echo "‚è≥ Waiting for container toolkit..."
              kubectl rollout status daemonset/nvidia-container-toolkit-daemonset -n gpu-operator --timeout=300s || {
                echo "‚ö†Ô∏è Container toolkit taking longer than expected"
              }
            fi
          else
            echo "‚ö†Ô∏è GPU Operator namespace not found"
          fi
          
          echo ""
          echo "üîç Checking GPU resources on nodes..."
          sleep 15
          
          GPU_AVAILABLE=false
          for i in {1..12}; do
            GPU_COUNT=$(kubectl get nodes -o json | jq -r '.items[].status.capacity."nvidia.com/gpu"' 2>/dev/null | grep -v "null" | head -1)
            
            if [ -n "$GPU_COUNT" ] && [ "$GPU_COUNT" != "null" ]; then
              echo "‚úÖ GPU resources detected: $GPU_COUNT GPU(s) per node"
              GPU_AVAILABLE=true
              break
            fi
            
            echo "‚è≥ Waiting for GPU resources... (attempt $i/12)"
            sleep 10
          done
          
          if [ "$GPU_AVAILABLE" = false ]; then
            echo "‚ö†Ô∏è WARNING: No GPU resources detected"
          fi
          
          echo ""
          echo "üìä Node GPU Status:"
          kubectl describe nodes | grep -A 10 "Capacity:" | grep -E "(nvidia.com/gpu|Allocatable)" || {
            echo "‚ùå No nvidia.com/gpu resources found"
          }
          
          echo ""
          echo "‚úÖ GPU configuration complete"

      - name: üîß Enable GPU Time-Slicing
        run: |
          echo "üîß Enabling GPU time-slicing for shared GPU access..."
          
          if ! kubectl get namespace gpu-operator &>/dev/null; then
            echo "‚ö†Ô∏è GPU Operator not found - skipping time-slicing"
            exit 0
          fi
          
          echo "üìù Creating time-slicing configuration..."
          cat <<'EOFCONFIG' | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: time-slicing-config
            namespace: gpu-operator
          data:
            any: |-
              version: v1
              flags:
                migStrategy: none
              sharing:
                timeSlicing:
                  resources:
                  - name: nvidia.com/gpu
                    replicas: 2
          EOFCONFIG
          
          echo "üîß Patching GPU Operator ClusterPolicy..."
          kubectl patch clusterpolicy cluster-policy -n gpu-operator --type merge -p '{"spec":{"devicePlugin":{"config":{"name":"time-slicing-config","default":"any"}}}}' || {
            echo "‚ö†Ô∏è Failed to patch ClusterPolicy"
          }
          
          echo "üîÑ Restarting device plugin to apply configuration..."
          kubectl delete pods -n gpu-operator -l app=nvidia-device-plugin-daemonset || true
          
          echo "‚è≥ Waiting for GPU device plugin to restart..."
          sleep 60
          
          echo "üîç Verifying GPU time-slicing..."
          for i in {1..10}; do
            GPU_CAPACITY=$(kubectl get nodes -o json | jq -r '.items[].status.capacity."nvidia.com/gpu"' | head -1)
            if [ "$GPU_CAPACITY" = "2" ]; then
              echo "‚úÖ GPU time-slicing enabled successfully - 2 GPU slots available"
              break
            fi
            echo "‚è≥ Waiting for GPU capacity to update... ($i/10)"
            sleep 5
          done
          
          echo ""
          echo "üìä Final GPU Capacity:"
          kubectl describe nodes | grep "nvidia.com/gpu:" | head -3
          echo ""
          echo "‚úÖ GPU time-slicing configuration applied"

      - name: üîê Setup cert-manager (FIXED - Rate Limit Protection)
        run: |
          echo "üîê Setting up cert-manager with rate limit protection..."
          
          # Check if cert-manager is already installed
          if ! kubectl get namespace cert-manager &>/dev/null; then
            echo "üì¶ Installing cert-manager..."
            kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.crds.yaml
            kubectl create namespace cert-manager
            kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
            
            echo "‚è≥ Waiting for cert-manager..."
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=cert-manager -n cert-manager --timeout=180s || {
              echo "‚ö†Ô∏è cert-manager taking longer than expected"
            }
            echo "‚úÖ cert-manager installed"
          else
            echo "‚úÖ cert-manager already installed"
            
            # Verify cert-manager is healthy
            READY_PODS=$(kubectl get pods -n cert-manager -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | grep -c "True" || echo "0")
            if [ "$READY_PODS" -ge 3 ]; then
              echo "‚úÖ cert-manager is healthy ($READY_PODS/3 pods ready)"
            else
              echo "‚ö†Ô∏è cert-manager may have issues ($READY_PODS/3 pods ready)"
              kubectl get pods -n cert-manager
            fi
          fi

      - name: üîê Setup Let's Encrypt Issuers (Smart Strategy)
        run: |
          echo "üîê Configuring Let's Encrypt with smart rate limit protection..."
          
          # Create staging issuer (unlimited)
          echo "üìù Creating Let's Encrypt STAGING issuer (unlimited for testing)..."
          cat <<EOF | kubectl apply -f -
          apiVersion: cert-manager.io/v1
          kind: ClusterIssuer
          metadata:
            name: letsencrypt-staging
          spec:
            acme:
              server: https://acme-staging-v02.api.letsencrypt.org/directory
              email: ${{ secrets.LETSENCRYPT_EMAIL }}
              privateKeySecretRef:
                name: letsencrypt-staging
              solvers:
              - http01:
                  ingress:
                    class: nginx
          EOF
          
          # Create production issuer
          echo "üìù Creating Let's Encrypt PRODUCTION issuer..."
          cat <<EOF | kubectl apply -f -
          apiVersion: cert-manager.io/v1
          kind: ClusterIssuer
          metadata:
            name: letsencrypt-prod
          spec:
            acme:
              server: https://acme-v02.api.letsencrypt.org/directory
              email: ${{ secrets.LETSENCRYPT_EMAIL }}
              privateKeySecretRef:
                name: letsencrypt-prod
              solvers:
              - http01:
                  ingress:
                    class: nginx
          EOF
          
          echo "‚è≥ Waiting for ClusterIssuers to be ready..."
          sleep 10
          
          # Verify issuers
          STAGING_READY=$(kubectl get clusterissuer letsencrypt-staging -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
          PROD_READY=$(kubectl get clusterissuer letsencrypt-prod -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
          
          echo "ClusterIssuer Status:"
          echo "  Staging: $STAGING_READY"
          echo "  Production: $PROD_READY"
          
          if [ "$STAGING_READY" = "True" ]; then
            echo "‚úÖ Staging issuer ready"
          else
            echo "‚ö†Ô∏è Staging issuer not ready yet"
          fi
          
          echo "‚úÖ Let's Encrypt issuers configured"

      - name: üåê Setup Ingress Controller
        run: |
          echo "üåê Setting up ingress-nginx controller..."
          
          detect_cloud() {
            if curl -s --max-time 2 http://169.254.169.254/latest/meta-data/ >/dev/null 2>&1; then
              return 0
            elif curl -s --max-time 2 -H "Metadata-Flavor: Google" http://metadata.google.internal >/dev/null 2>&1; then
              return 0
            elif curl -s --max-time 2 -H "Metadata: true" http://169.254.169.254/metadata/instance >/dev/null 2>&1; then
              return 0
            else
              return 1
            fi
          }
          
          if ! kubectl get namespace ingress-nginx >/dev/null 2>&1; then
            echo "üì¶ Installing ingress-nginx..."
            
            if detect_cloud; then
              echo "‚òÅÔ∏è  Cloud environment detected"
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.4/deploy/static/provider/cloud/deploy.yaml
            else
              echo "üîß Bare metal environment detected"
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.4/deploy/static/provider/baremetal/deploy.yaml
              sleep 15
              kubectl patch deployment ingress-nginx-controller -n ingress-nginx --type='json' -p='[{"op":"add","path":"/spec/template/spec/hostNetwork","value":true},{"op":"add","path":"/spec/template/spec/dnsPolicy","value":"ClusterFirstWithHostNet"}]'
            fi
          else
            echo "‚úÖ ingress-nginx already exists"
          fi
          
          echo "‚è≥ Waiting for ingress controller..."
          kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=300s || {
            echo "‚ö†Ô∏è Controller taking longer than expected"
          }
          echo "‚úÖ Ingress controller ready"

      - name: üèóÔ∏è Create Namespace
        run: |
          if [ -f k8s/namespace.yaml ]; then
            kubectl apply -f k8s/namespace.yaml
          else
            kubectl get ns "$KUBE_NAMESPACE" >/dev/null 2>&1 || kubectl create ns "$KUBE_NAMESPACE"
          fi

      - name: üîê Create Docker Registry Secret
        run: |
          kubectl create secret docker-registry dockerhub-secret \
            --docker-server=docker.io \
            --docker-username='${{ secrets.DOCKERHUB_USERNAME }}' \
            --docker-password='${{ secrets.DOCKERHUB_TOKEN }}' \
            --docker-email='${{ secrets.DOCKERHUB_EMAIL }}' \
            --namespace="$KUBE_NAMESPACE" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: üîß Prepare manifests
        run: |
          mkdir -p /tmp/k8s-updated
          cp -r k8s/* /tmp/k8s-updated/ || true
          for service in june-stt june-tts june-orchestrator june-idp june-web june-dark; do
            if [ -f "/tmp/k8s-updated/${service}-deployment.yaml" ]; then
              sed -i "s|image: $REGISTRY/${service}:.*|image: $REGISTRY/${service}:$IMAGE_TAG|g" "/tmp/k8s-updated/${service}-deployment.yaml"
            elif [ -f "/tmp/k8s-updated/complete-manifests.yaml" ]; then
              sed -i "s|image: ozzuworld/${service}:.*|image: $REGISTRY/${service}:$IMAGE_TAG|g" "/tmp/k8s-updated/complete-manifests.yaml"
            fi
          done

      - name: üóÑÔ∏è Deploy PostgreSQL
        run: |
          echo "üóÑÔ∏è Deploying PostgreSQL..."
          if kubectl get statefulset postgresql -n "$KUBE_NAMESPACE" &>/dev/null; then
            echo "‚úÖ PostgreSQL already exists"
          else
            kubectl apply -f k8s/postgresql-deployment.yaml
          fi
          
          echo "‚è≥ Waiting for PostgreSQL..."
          kubectl wait --for=condition=ready pod -l app=postgresql -n "$KUBE_NAMESPACE" --timeout=180s || {
            echo "‚ö†Ô∏è PostgreSQL not ready yet"
          }

      - name: üöÄ Deploy services
        run: |
          echo "üöÄ Deploying services..."
          if [ -f "/tmp/k8s-updated/complete-manifests.yaml" ]; then
            kubectl apply -n "$KUBE_NAMESPACE" -f /tmp/k8s-updated/complete-manifests.yaml
          else
            for file in /tmp/k8s-updated/june-*-deployment.yaml; do
              [ -f "$file" ] && kubectl apply -n "$KUBE_NAMESPACE" -f "$file"
            done
          fi

      - name: üåê Apply Ingress with Smart Certificate Management (FIXED)
        run: |
          echo "üåê Deploying ingress with smart certificate management..."
          
          # Determine certificate strategy
          CERT_ISSUER="letsencrypt-staging"  # Default to staging (safe)
          CERT_ACTION="keeping_existing"
          
          # Check if certificate already exists and is valid
          if kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" &>/dev/null; then
            CERT_READY=$(kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "False")
            CURRENT_ISSUER=$(kubectl get ingress june-ingress -n "$KUBE_NAMESPACE" -o jsonpath='{.metadata.annotations.cert-manager\.io/cluster-issuer}' 2>/dev/null || echo "")
            
            if [ "$CERT_READY" = "True" ]; then
              echo "‚úÖ Valid certificate already exists"
              echo "   Current issuer: $CURRENT_ISSUER"
              CERT_ISSUER="$CURRENT_ISSUER"
              CERT_ACTION="reusing_valid_cert"
              
              # Check if user explicitly wants to promote to production
              if [ "${{ github.event.inputs.promote_to_production_cert }}" = "true" ] && [ "$CURRENT_ISSUER" != "letsencrypt-prod" ]; then
                echo "üîÑ User requested promotion to production certificate"
                CERT_ISSUER="letsencrypt-prod"
                CERT_ACTION="promoting_to_prod"
              fi
            else
              echo "‚ö†Ô∏è Certificate exists but not ready (status: $CERT_READY)"
              echo "   Will use staging issuer to avoid rate limits"
              CERT_ISSUER="letsencrypt-staging"
              CERT_ACTION="recreating_with_staging"
            fi
          else
            echo "‚ÑπÔ∏è No certificate exists yet"
            echo "   Will create new certificate using staging issuer (safe)"
            CERT_ISSUER="letsencrypt-staging"
            CERT_ACTION="creating_new_staging"
          fi
          
          echo ""
          echo "üìã Certificate Strategy:"
          echo "   Issuer: $CERT_ISSUER"
          echo "   Action: $CERT_ACTION"
          echo ""
          
          # If promoting to production, clean up old cert first
          if [ "$CERT_ACTION" = "promoting_to_prod" ]; then
            echo "üîÑ Cleaning up staging certificate for promotion..."
            kubectl delete certificate allsafe-tls -n "$KUBE_NAMESPACE" || true
            kubectl delete certificaterequest --all -n "$KUBE_NAMESPACE" || true
            kubectl delete secret allsafe-tls -n "$KUBE_NAMESPACE" || true
            sleep 5
          fi
          
          # Apply ingress with determined issuer
          cat <<EOF | kubectl apply -f -
          apiVersion: networking.k8s.io/v1
          kind: Ingress
          metadata:
            name: june-ingress
            namespace: $KUBE_NAMESPACE
            annotations:
              cert-manager.io/cluster-issuer: $CERT_ISSUER
              kubernetes.io/ingress.class: nginx
              nginx.ingress.kubernetes.io/ssl-redirect: "false"
              nginx.ingress.kubernetes.io/force-ssl-redirect: "false"
              nginx.ingress.kubernetes.io/enable-cors: "true"
              nginx.ingress.kubernetes.io/cors-allow-origin: "*"
              nginx.ingress.kubernetes.io/proxy-body-size: "100m"
              nginx.ingress.kubernetes.io/proxy-connect-timeout: "300"
              nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
              nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
          spec:
            ingressClassName: nginx
            tls:
            - hosts:
              - api.allsafe.world
              - idp.allsafe.world
              - stt.allsafe.world
              - tts.allsafe.world
              secretName: allsafe-tls
            rules:
            - host: api.allsafe.world
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: june-orchestrator
                      port:
                        number: 8080
            - host: idp.allsafe.world
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: june-idp
                      port:
                        number: 8080
            - host: stt.allsafe.world
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: june-stt
                      port:
                        number: 8080
            - host: tts.allsafe.world
              http:
                paths:
                - path: /
                  pathType: Prefix
                  backend:
                    service:
                      name: june-tts
                      port:
                        number: 8000
          EOF
          
          echo "‚úÖ Ingress applied with issuer: $CERT_ISSUER"

      - name: ‚è≥ Monitor Certificate Issuance
        run: |
          echo "‚è≥ Monitoring certificate issuance..."
          
          # Give cert-manager time to process
          sleep 20
          
          # Monitor for up to 5 minutes
          for i in {1..20}; do
            if ! kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" &>/dev/null; then
              echo "‚è≥ Waiting for certificate resource to be created... ($i/20)"
              sleep 15
              continue
            fi
            
            CERT_STATUS=$(kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
            
            if [ "$CERT_STATUS" = "True" ]; then
              echo "‚úÖ Certificate successfully issued!"
              
              # Show certificate details
              ISSUER=$(kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" -o jsonpath='{.spec.issuerRef.name}')
              NOT_AFTER=$(kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" -o jsonpath='{.status.notAfter}')
              
              echo ""
              echo "üìã Certificate Details:"
              echo "   Issuer: $ISSUER"
              echo "   Valid until: $NOT_AFTER"
              
              # Check if it's a staging cert
              if [ "$ISSUER" = "letsencrypt-staging" ]; then
                echo ""
                echo "‚ÑπÔ∏è Using STAGING certificate (browser will show warning)"
                echo "   This is NORMAL and protects against rate limits"
                echo ""
                echo "üéØ To promote to production certificate:"
                echo "   1. Verify staging certificate works correctly"
                echo "   2. Use workflow_dispatch with 'promote_to_production_cert: true'"
                echo "   3. Or manually run:"
                echo "      kubectl annotate ingress june-ingress -n $KUBE_NAMESPACE --overwrite cert-manager.io/cluster-issuer=letsencrypt-prod"
                echo "      kubectl delete certificate allsafe-tls -n $KUBE_NAMESPACE"
              fi
              
              break
            elif [ "$CERT_STATUS" = "False" ]; then
              REASON=$(kubectl get certificate allsafe-tls -n "$KUBE_NAMESPACE" -o jsonpath='{.status.conditions[?(@.type=="Ready")].message}' 2>/dev/null || echo "Processing")
              echo "‚è≥ Certificate not ready: $REASON ($i/20)"
              
              # Check for rate limit in cert-manager logs
              if kubectl logs -n cert-manager -l app=cert-manager --tail=50 2>/dev/null | grep -q "rateLimited"; then
                echo ""
                echo "‚ùå RATE LIMIT DETECTED!"
                echo "   Switching to staging issuer to avoid further rate limit issues..."
                
                kubectl annotate ingress june-ingress -n "$KUBE_NAMESPACE" --overwrite \
                  cert-manager.io/cluster-issuer=letsencrypt-staging
                kubectl delete certificate allsafe-tls -n "$KUBE_NAMESPACE" || true
                kubectl delete certificaterequest --all -n "$KUBE_NAMESPACE" || true
                
                echo "   Retrying with staging issuer..."
                sleep 10
                i=0  # Reset counter
              fi
            else
              echo "‚è≥ Waiting for certificate... status: $CERT_STATUS ($i/20)"
            fi
            
            sleep 15
          done
          
          # Final status
          echo ""
          echo "üìä Final Certificate Status:"
          kubectl get certificate -n "$KUBE_NAMESPACE" || echo "No certificates found"
          
          echo ""
          echo "üìã Certificate Details:"
          kubectl describe certificate allsafe-tls -n "$KUBE_NAMESPACE" 2>/dev/null | tail -20 || echo "Certificate not found"

      - name: ‚è≥ Wait for deployments
        run: |
          echo "‚è≥ Waiting for deployments..."
          for deployment in $(kubectl get deployments -n "$KUBE_NAMESPACE" -o jsonpath='{.items[*].metadata.name}'); do
            kubectl rollout status deployment/"$deployment" -n "$KUBE_NAMESPACE" --timeout=300s || true
          done

      - name: üìä Final status
        if: always()
        run: |
          echo "üìä Deployment Status:"
          kubectl get all -n "$KUBE_NAMESPACE" -o wide || true
          echo ""
          echo "üéÆ GPU Status:"
          kubectl describe nodes | grep "nvidia.com/gpu" || echo "No GPU info"
          echo ""
          echo "üîê Certificate Status:"
          kubectl get certificate,certificaterequest,order,challenge -n "$KUBE_NAMESPACE" 2>/dev/null || echo "No certificate resources"
          echo ""
          echo "‚úÖ Deployment complete"
          
          # Show useful next steps
          CERT_ISSUER=$(kubectl get ingress june-ingress -n "$KUBE_NAMESPACE" -o jsonpath='{.metadata.annotations.cert-manager\.io/cluster-issuer}' 2>/dev/null || echo "unknown")
          
          if [ "$CERT_ISSUER" = "letsencrypt-staging" ]; then
            echo ""
            echo "‚ÑπÔ∏è Currently using STAGING certificates"
            echo ""
            echo "üéØ To promote to PRODUCTION:"
            echo "   Run this workflow again with:"
            echo "   ‚Ä¢ promote_to_production_cert: true"
            echo ""
            echo "‚ö†Ô∏è Only promote when:"
            echo "   ‚Ä¢ Staging certificates work correctly"
            echo "   ‚Ä¢ You're ready for production"
            echo "   ‚Ä¢ You haven't hit rate limits recently"
          elif [ "$CERT_ISSUER" = "letsencrypt-prod" ]; then
            echo ""
            echo "‚úÖ Using PRODUCTION certificates"
            echo "   No browser warnings expected"
          fi