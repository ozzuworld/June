name: 🚀 Complete June Services CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
    paths-ignore: [ 'README.md', 'docs/**', '.gitignore' ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Image tag to deploy'
        required: true
        default: 'latest'
        type: string
      environment:
        description: 'Target environment'
        required: true
        default: 'production'
        type: choice
        options: 
          - production
          - staging
          - development
      services:
        description: 'Services to deploy (comma-separated, empty for all)'
        required: false
        default: ''
        type: string
      force_restart:
        description: 'Force restart deployments'
        required: false
        default: false
        type: boolean
      build_images:
        description: 'Build and push Docker images'
        required: false
        default: true
        type: boolean

env:
  REGISTRY: docker.io/${{ secrets.DOCKERHUB_USERNAME }}
  KUBE_NAMESPACE: june-services
  IMAGE_TAG: ${{ github.event.inputs.image_tag || github.sha }}

permissions:
  contents: read
  packages: write

jobs:
  build-and-push:
    name: 🔨 Build & Push Images
    runs-on: self-hosted
    if: github.event.inputs.build_images != 'false'
    strategy:
      fail-fast: false
      matrix:
        service: [june-stt, june-tts, june-orchestrator, june-idp, june-web, june-dark]
    steps:
      - name: 📦 Checkout repository
        uses: actions/checkout@v4

      - name: 🔐 Login to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: 🔧 Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: 📝 Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ matrix.service }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix=sha-
            type=raw,value=latest,enable={{is_default_branch}}
            type=raw,value=${{ env.IMAGE_TAG }}

      - name: 🏗️ Build and push
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.service }}
          file: ./${{ matrix.service }}/Dockerfile
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          platforms: linux/amd64

  deploy:
    name: 🚀 Deploy to K8s
    runs-on: self-hosted
    needs: build-and-push
    if: always() && (needs.build-and-push.result == 'success' || needs.build-and-push.result == 'skipped')

    steps:
      - name: 📦 Checkout repository
        uses: actions/checkout@v4

      - name: 🔍 Verify k8s manifest files
        run: |
          set -e
          echo "🔍 Verifying k8s manifest files..."
          ls -la k8s || true
          test -f k8s/namespace.yaml || echo "⚠️ k8s/namespace.yaml not found"

      - name: 🔍 Verify Kubernetes connection
        run: |
          echo "🔍 Testing Kubernetes connection..."
          kubectl cluster-info
          kubectl get nodes -o wide

      - name: 🎮 Configure GPU Support
        run: |
          echo "🎮 Configuring GPU node labels and checking GPU Operator..."
          
          echo "🏷️  Labeling nodes for GPU workloads..."
          for node in $(kubectl get nodes -o name); do
            kubectl label $node gpu=true --overwrite
            echo "✅ Labeled: $node"
          done
          
          echo ""
          echo "🔍 Checking GPU Operator status..."
          if kubectl get namespace gpu-operator &>/dev/null; then
            echo "✅ GPU Operator namespace exists"
            echo "📊 GPU Operator pods:"
            kubectl get pods -n gpu-operator
            
            echo ""
            echo "⏳ Waiting for GPU Operator components..."
            
            if kubectl get daemonset -n gpu-operator nvidia-device-plugin-daemonset &>/dev/null; then
              echo "⏳ Waiting for device plugin..."
              kubectl rollout status daemonset/nvidia-device-plugin-daemonset -n gpu-operator --timeout=300s || {
                echo "⚠️ Device plugin taking longer than expected"
              }
            fi
            
            if kubectl get daemonset -n gpu-operator nvidia-container-toolkit-daemonset &>/dev/null; then
              echo "⏳ Waiting for container toolkit..."
              kubectl rollout status daemonset/nvidia-container-toolkit-daemonset -n gpu-operator --timeout=300s || {
                echo "⚠️ Container toolkit taking longer than expected"
              }
            fi
          else
            echo "⚠️ GPU Operator namespace not found"
          fi
          
          echo ""
          echo "🔍 Checking GPU resources on nodes..."
          sleep 15
          
          GPU_AVAILABLE=false
          for i in {1..12}; do
            GPU_COUNT=$(kubectl get nodes -o json | jq -r '.items[].status.capacity."nvidia.com/gpu"' 2>/dev/null | grep -v "null" | head -1)
            
            if [ -n "$GPU_COUNT" ] && [ "$GPU_COUNT" != "null" ]; then
              echo "✅ GPU resources detected: $GPU_COUNT GPU(s) per node"
              GPU_AVAILABLE=true
              break
            fi
            
            echo "⏳ Waiting for GPU resources... (attempt $i/12)"
            sleep 10
          done
          
          if [ "$GPU_AVAILABLE" = false ]; then
            echo "⚠️ WARNING: No GPU resources detected"
          fi
          
          echo ""
          echo "📊 Node GPU Status:"
          kubectl describe nodes | grep -A 10 "Capacity:" | grep -E "(nvidia.com/gpu|Allocatable)" || {
            echo "❌ No nvidia.com/gpu resources found"
          }
          
          echo ""
          echo "✅ GPU configuration complete"

      - name: 🔧 Enable GPU Time-Slicing
        run: |
          echo "🔧 Enabling GPU time-slicing for shared GPU access..."
          
          if ! kubectl get namespace gpu-operator &>/dev/null; then
            echo "⚠️ GPU Operator not found - skipping time-slicing"
            exit 0
          fi
          
          echo "📝 Creating time-slicing configuration..."
          cat <<'EOFCONFIG' | kubectl apply -f -
          apiVersion: v1
          kind: ConfigMap
          metadata:
            name: time-slicing-config
            namespace: gpu-operator
          data:
            any: |-
              version: v1
              flags:
                migStrategy: none
              sharing:
                timeSlicing:
                  resources:
                  - name: nvidia.com/gpu
                    replicas: 2
          EOFCONFIG
          
          echo "🔧 Patching GPU Operator ClusterPolicy..."
          kubectl patch clusterpolicy cluster-policy -n gpu-operator --type merge -p '{"spec":{"devicePlugin":{"config":{"name":"time-slicing-config","default":"any"}}}}' || {
            echo "⚠️ Failed to patch ClusterPolicy"
          }
          
          echo "🔄 Restarting device plugin to apply configuration..."
          kubectl delete pods -n gpu-operator -l app=nvidia-device-plugin-daemonset || true
          
          echo "⏳ Waiting for GPU device plugin to restart..."
          sleep 60
          
          echo "🔍 Verifying GPU time-slicing..."
          for i in {1..10}; do
            GPU_CAPACITY=$(kubectl get nodes -o json | jq -r '.items[].status.capacity."nvidia.com/gpu"' | head -1)
            if [ "$GPU_CAPACITY" = "2" ]; then
              echo "✅ GPU time-slicing enabled successfully - 2 GPU slots available"
              break
            fi
            echo "⏳ Waiting for GPU capacity to update... ($i/10)"
            sleep 5
          done
          
          echo ""
          echo "📊 Final GPU Capacity:"
          kubectl describe nodes | grep "nvidia.com/gpu:" | head -3
          echo ""
          echo "✅ GPU time-slicing configuration applied"

      - name: 🔐 Setup cert-manager and Let's Encrypt
        run: |
          echo "🔐 Setting up TLS certificates with cert-manager..."
          
          if ! kubectl get namespace cert-manager &>/dev/null; then
            echo "📦 Installing cert-manager..."
            kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.crds.yaml
            kubectl create namespace cert-manager
            kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
            
            echo "⏳ Waiting for cert-manager..."
            kubectl wait --for=condition=ready pod -l app.kubernetes.io/instance=cert-manager -n cert-manager --timeout=180s || {
              echo "⚠️ cert-manager taking longer than expected"
            }
            echo "✅ cert-manager installed"
          else
            echo "✅ cert-manager already installed"
          fi
          
          echo "🔧 Creating Let's Encrypt issuers..."
          cat <<'EOFISSUER' | kubectl apply -f -
          apiVersion: cert-manager.io/v1
          kind: ClusterIssuer
          metadata:
            name: letsencrypt-prod
          spec:
            acme:
              server: https://acme-v02.api.letsencrypt.org/directory
              email: ${{ secrets.LETSENCRYPT_EMAIL }}
              privateKeySecretRef:
                name: letsencrypt-prod
              solvers:
              - http01:
                  ingress:
                    class: nginx
          ---
          apiVersion: cert-manager.io/v1
          kind: ClusterIssuer
          metadata:
            name: letsencrypt-staging
          spec:
            acme:
              server: https://acme-staging-v02.api.letsencrypt.org/directory
              email: ${{ secrets.LETSENCRYPT_EMAIL }}
              privateKeySecretRef:
                name: letsencrypt-staging
              solvers:
              - http01:
                  ingress:
                    class: nginx
          EOFISSUER
          
          echo "✅ Let's Encrypt issuers configured"

      - name: 🌐 Setup Ingress Controller
        run: |
          echo "🌐 Setting up ingress-nginx controller..."
          
          detect_cloud() {
            if curl -s --max-time 2 http://169.254.169.254/latest/meta-data/ >/dev/null 2>&1; then
              return 0
            elif curl -s --max-time 2 -H "Metadata-Flavor: Google" http://metadata.google.internal >/dev/null 2>&1; then
              return 0
            elif curl -s --max-time 2 -H "Metadata: true" http://169.254.169.254/metadata/instance >/dev/null 2>&1; then
              return 0
            else
              return 1
            fi
          }
          
          if ! kubectl get namespace ingress-nginx >/dev/null 2>&1; then
            echo "📦 Installing ingress-nginx..."
            
            if detect_cloud; then
              echo "☁️  Cloud environment detected"
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.4/deploy/static/provider/cloud/deploy.yaml
            else
              echo "🔧 Bare metal environment detected"
              kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.9.4/deploy/static/provider/baremetal/deploy.yaml
              sleep 15
              kubectl patch deployment ingress-nginx-controller -n ingress-nginx --type='json' -p='[{"op":"add","path":"/spec/template/spec/hostNetwork","value":true},{"op":"add","path":"/spec/template/spec/dnsPolicy","value":"ClusterFirstWithHostNet"}]'
            fi
          else
            echo "✅ ingress-nginx already exists"
          fi
          
          echo "⏳ Waiting for ingress controller..."
          kubectl wait --namespace ingress-nginx --for=condition=ready pod --selector=app.kubernetes.io/component=controller --timeout=300s || {
            echo "⚠️ Controller taking longer than expected"
          }
          echo "✅ Ingress controller ready"

      - name: 🏗️ Create Namespace
        run: |
          if [ -f k8s/namespace.yaml ]; then
            kubectl apply -f k8s/namespace.yaml
          else
            kubectl get ns "$KUBE_NAMESPACE" >/dev/null 2>&1 || kubectl create ns "$KUBE_NAMESPACE"
          fi

      - name: 🔐 Create Docker Registry Secret
        run: |
          kubectl create secret docker-registry dockerhub-secret \
            --docker-server=docker.io \
            --docker-username='${{ secrets.DOCKERHUB_USERNAME }}' \
            --docker-password='${{ secrets.DOCKERHUB_TOKEN }}' \
            --docker-email='${{ secrets.DOCKERHUB_EMAIL }}' \
            --namespace="$KUBE_NAMESPACE" \
            --dry-run=client -o yaml | kubectl apply -f -

      - name: 🔧 Prepare manifests
        run: |
          mkdir -p /tmp/k8s-updated
          cp -r k8s/* /tmp/k8s-updated/ || true
          for service in june-stt june-tts june-orchestrator june-idp june-web june-dark; do
            if [ -f "/tmp/k8s-updated/${service}-deployment.yaml" ]; then
              sed -i "s|image: $REGISTRY/${service}:.*|image: $REGISTRY/${service}:$IMAGE_TAG|g" "/tmp/k8s-updated/${service}-deployment.yaml"
            elif [ -f "/tmp/k8s-updated/complete-manifests.yaml" ]; then
              sed -i "s|image: ozzuworld/${service}:.*|image: $REGISTRY/${service}:$IMAGE_TAG|g" "/tmp/k8s-updated/complete-manifests.yaml"
            fi
          done

      - name: 🗄️ Deploy PostgreSQL
        run: |
          echo "🗄️ Deploying PostgreSQL..."
          if kubectl get statefulset postgresql -n "$KUBE_NAMESPACE" &>/dev/null; then
            echo "✅ PostgreSQL already exists"
          else
            kubectl apply -f k8s/postgresql-deployment.yaml
          fi
          
          echo "⏳ Waiting for PostgreSQL..."
          kubectl wait --for=condition=ready pod -l app=postgresql -n "$KUBE_NAMESPACE" --timeout=180s || {
            echo "⚠️ PostgreSQL not ready yet"
          }

      - name: 🚀 Deploy services
        run: |
          echo "🚀 Deploying services..."
          if [ -f "/tmp/k8s-updated/complete-manifests.yaml" ]; then
            kubectl apply -n "$KUBE_NAMESPACE" -f /tmp/k8s-updated/complete-manifests.yaml
          else
            for file in /tmp/k8s-updated/june-*-deployment.yaml; do
              [ -f "$file" ] && kubectl apply -n "$KUBE_NAMESPACE" -f "$file"
            done
          fi

      - name: 🌐 Apply ingress
        run: |
          echo "🌐 Applying ingress..."
          if [ -f "/tmp/k8s-updated/ingress.yaml" ]; then
            kubectl apply -f /tmp/k8s-updated/ingress.yaml
          fi

      - name: ⏳ Wait for deployments
        run: |
          echo "⏳ Waiting for deployments..."
          for deployment in $(kubectl get deployments -n "$KUBE_NAMESPACE" -o jsonpath='{.items[*].metadata.name}'); do
            kubectl rollout status deployment/"$deployment" -n "$KUBE_NAMESPACE" --timeout=300s || true
          done

      - name: 📊 Final status
        if: always()
        run: |
          echo "📊 Deployment Status:"
          kubectl get all -n "$KUBE_NAMESPACE" -o wide || true
          echo ""
          echo "🎮 GPU Status:"
          kubectl describe nodes | grep "nvidia.com/gpu" || echo "No GPU info"
          echo ""
          echo "✅ Deployment complete"