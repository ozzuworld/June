# SkyPilot task definition for June GPU services
name: june-gpu-services

resources:
  accelerators: RTX4090:1  # Preferred GPU
  cloud: vast
  disk_size: 50
  
  # Fallback GPUs (SkyPilot will try these in order if RTX4060 unavailable)
  any_of:
    - accelerators: RTX4060:1
    - accelerators: RTX3060:1
    - accelerators: RTX4060Ti:1
    - accelerators: RTX3060Ti:1

# Budget constraints
max_price: 0.20  # USD per hour

# Setup phase (runs once when instance is created)
setup: |
  set -e
  
  # Install Tailscale
  echo "ðŸ“¦ Installing Tailscale..."
  curl -fsSL https://tailscale.com/install.sh | sh
  
  # Connect to Headscale VPN
  echo "ðŸ”— Connecting to Headscale VPN..."
  tailscale up --authkey=${HEADSCALE_AUTH_KEY} \
    --login-server=https://headscale.ozzu.world \
    --hostname=skypilot-gpu-${SKYPILOT_TASK_ID}
  
  # Install Docker Compose if needed
  if ! command -v docker-compose &> /dev/null; then
    echo "ðŸ“¦ Installing Docker Compose..."
    curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" \
      -o /usr/local/bin/docker-compose
    chmod +x /usr/local/bin/docker-compose
  fi
  
  # Verify GPU access
  nvidia-smi
  
  echo "âœ… Setup complete"

# Run phase (your actual GPU services)
run: |
  set -e
  
  # Create compose file for split services
  cat > docker-compose.yaml << 'EOF'
  version: '3.8'
  
  services:
    june-tts:
      image: ozzuworld/june-tts:latest
      container_name: june-tts
      restart: unless-stopped
      deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: 1
                capabilities: [gpu]
      environment:
        - TTS_PORT=8000
        - TTS_HOME=/app/models
        - TTS_CACHE_PATH=/app/cache
        - ORCHESTRATOR_URL=${ORCHESTRATOR_URL}
      ports:
        - "8000:8000"
      volumes:
        - tts-models:/app/models
        - tts-cache:/app/cache
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
        interval: 30s
        timeout: 10s
        retries: 3
    
    june-stt:
      image: ozzuworld/june-stt:latest
      container_name: june-stt
      restart: unless-stopped
      deploy:
        resources:
          reservations:
            devices:
              - driver: nvidia
                count: 1
                capabilities: [gpu]
      environment:
        - STT_PORT=8001
        - WHISPER_DEVICE=cuda
        - WHISPER_COMPUTE_TYPE=float16
        - ORCHESTRATOR_URL=${ORCHESTRATOR_URL}
        - LIVEKIT_URL=${LIVEKIT_URL}
        - ROOM_NAME=ozzu-main
      ports:
        - "8001:8001"
      volumes:
        - stt-models:/app/models
        - stt-cache:/app/cache
      healthcheck:
        test: ["CMD", "curl", "-f", "http://localhost:8001/healthz"]
        interval: 30s
        timeout: 10s
        retries: 3
  
  volumes:
    tts-models:
    tts-cache:
    stt-models:
    stt-cache:
  EOF
  
  # Start services
  echo "ðŸš€ Starting GPU services..."
  docker-compose up -d
  
  # Wait for services to be healthy
  echo "â³ Waiting for services to be healthy..."
  for i in {1..30}; do
    if curl -sf http://localhost:8000/healthz && \
       curl -sf http://localhost:8001/healthz; then
      echo "âœ… All services healthy"
      break
    fi
    echo "Waiting... ($i/30)"
    sleep 10
  done
  
  # Show Tailscale status
  echo "ðŸ“Š Tailscale Status:"
  tailscale status
  
  # Keep container running and show logs
  docker-compose logs -f

# Environment variables (injected from secrets)
envs:
  HEADSCALE_AUTH_KEY: ${HEADSCALE_AUTH_KEY}
  ORCHESTRATOR_URL: ${ORCHESTRATOR_URL}
  LIVEKIT_URL: ${LIVEKIT_URL}

# File mounts (optional - for persistent model storage)
file_mounts:
  /sky-models:
    source: ~/.sky/june-models
    mode: MOUNT