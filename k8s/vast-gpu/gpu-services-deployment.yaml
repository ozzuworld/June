# Combined GPU services deployment for STT+TTS on single Vast.ai instance
apiVersion: apps/v1
kind: Deployment
metadata:
  name: june-gpu-services
  namespace: june-services
  labels:
    app: june-gpu-services
    component: gpu-services
spec:
  replicas: 1
  selector:
    matchLabels:
      app: june-gpu-services
  template:
    metadata:
      labels:
        app: june-gpu-services
        component: gpu-services
      annotations:
        # Vast.ai instance configuration - Optimized for availability
        vast.ai/gpu-type: "RTX 4060"
        vast.ai/gpu-fallbacks: "RTX 3060,RTX 3060 Ti,RTX 4060 Ti,RTX 4070,RTX 3070,RTX 3080,RTX 3090,RTX A5000"
        vast.ai/price-max: "0.50"  # Increased budget for more reliable hosts
        vast.ai/region: "North America"
        vast.ai/memory: "12GB"
        vast.ai/disk: "50"
        vast.ai/image: "pytorch/pytorch:2.2.0-cuda12.1-cudnn8-devel"
        vast.ai/env: "-p 8000:8000 -p 8001:8001"
        vast.ai/runtype: "ssh_direct"
        vast.ai/onstart-cmd: "pip install -q fastapi uvicorn aiohttp && echo 'Container ready for June services'"
    spec:
      # Target the Virtual Kubelet node explicitly
      nodeName: vast-gpu-node-python
      
      # Required tolerations for VK scheduling
      tolerations:
      - key: "vast.ai/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      - key: "virtual-kubelet.io/provider"
        operator: "Equal"
        value: "vast"
        effect: "NoSchedule"
      
      containers:
      - name: june-multi-gpu
        image: ozzuworld/june-multi-gpu:latest
        
        # Expose both STT and TTS services
        ports:
        - containerPort: 8000
          name: tts-api
          protocol: TCP
        - containerPort: 8001
          name: stt-api
          protocol: TCP
        
        # Environment configuration for combined service
        env:
        - name: STT_PORT
          value: "8001"
        - name: TTS_PORT
          value: "8000"
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: WHISPER_DEVICE
          value: "cuda"
        - name: WHISPER_COMPUTE_TYPE
          value: "float16"
        - name: TTS_CACHE_PATH
          value: "/app/cache"
        - name: TTS_HOME
          value: "/app/models"
        - name: COQUI_TOS_AGREED
          value: "1"
        
        # LiveKit and orchestrator connectivity
        - name: LIVEKIT_URL
          valueFrom:
            configMapKeyRef:
              name: june-config
              key: livekit-url
              optional: true
        - name: LIVEKIT_API_KEY
          valueFrom:
            secretKeyRef:
              name: june-secrets
              key: livekit-api-key
              optional: true
        - name: LIVEKIT_API_SECRET
          valueFrom:
            secretKeyRef:
              name: june-secrets
              key: livekit-api-secret
              optional: true
        - name: ORCHESTRATOR_URL
          valueFrom:
            configMapKeyRef:
              name: june-config
              key: orchestrator-url
              optional: true
        - name: BEARER_TOKEN
          valueFrom:
            secretKeyRef:
              name: june-secrets
              key: bearer-token
              optional: true
        
        # Resource requirements for GPU workload
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: "16Gi"
            cpu: "8"
          requests:
            nvidia.com/gpu: 1
            memory: "12Gi"
            cpu: "4"
        
        # Volume mounts for model caching
        volumeMounts:
        - name: models-cache
          mountPath: /app/models
        - name: temp-cache
          mountPath: /app/cache
        
        # Startup probe to handle long GPU initialization - CRITICAL FIX
        startupProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 120     # Wait 2 minutes before first check
          periodSeconds: 30            # Check every 30 seconds
          timeoutSeconds: 15           # 15 second timeout per check
          failureThreshold: 20         # Allow up to 10 more minutes (20 * 30s = 600s)
          successThreshold: 1          # Only need 1 success to mark ready
        
        # Liveness probe - More generous timeouts
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 300     # Increased from 120 to 5 minutes
          periodSeconds: 60            # Check every minute instead of 30s
          timeoutSeconds: 30           # Increased timeout to 30s
          failureThreshold: 5          # Allow 5 failures before restart
        
        # Readiness probe - Even more generous
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 240     # Increased from 60 to 4 minutes
          periodSeconds: 30            # Check every 30 seconds
          timeoutSeconds: 20           # Increased timeout to 20s
          failureThreshold: 10         # Allow many failures during startup
          successThreshold: 2          # Require 2 consecutive successes
      
      # Volumes for model and cache storage
      volumes:
      - name: models-cache
        emptyDir:
          sizeLimit: 10Gi
      - name: temp-cache
        emptyDir:
          sizeLimit: 5Gi
      
      restartPolicy: Always
      terminationGracePeriodSeconds: 60  # Increased from 30 for graceful shutdown
---
# Service to expose the combined GPU services
apiVersion: v1
kind: Service
metadata:
  name: june-gpu-services
  namespace: june-services
  labels:
    app: june-gpu-services
    component: gpu-services
spec:
  selector:
    app: june-gpu-services
  ports:
  - name: tts-api
    port: 8000
    targetPort: 8000
    protocol: TCP
  - name: stt-api
    port: 8001
    targetPort: 8001
    protocol: TCP
  type: ClusterIP