# ==============================================================================
# GPU SHARING SOLUTION FOR JUNE TTS & STT
# ==============================================================================
# This uses NVIDIA Time-Slicing to share a single GPU across multiple pods
# Reference: https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/gpu-sharing.html

# Step 1: Create ConfigMap for GPU Time-Slicing
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: time-slicing-config
  namespace: gpu-operator
data:
  any: |-
    version: v1
    sharing:
      timeSlicing:
        replicas: 4  # Allow 4 pods to share the GPU
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
        - name: nvidia.com/gpu
          replicas: 4

---
# Step 2: Update ClusterPolicy to enable time-slicing
apiVersion: v1
kind: ConfigMap
metadata:
  name: device-plugin-config
  namespace: gpu-operator
data:
  config.yaml: |
    version: v1
    flags:
      migStrategy: none
    sharing:
      timeSlicing:
        renameByDefault: false
        failRequestsGreaterThanOne: false
        resources:
        - name: nvidia.com/gpu
          replicas: 4  # 4 replicas per GPU

---
# Step 3: Updated TTS Deployment with GPU Sharing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: june-tts
  namespace: june
  labels:
    app: june-tts
spec:
  replicas: 1
  selector:
    matchLabels:
      app: june-tts
  template:
    metadata:
      labels:
        app: june-tts
    spec:
      # Node selector for GPU nodes
      nodeSelector:
        gpu: "true"
      
      # Tolerate GPU taints
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      
      # Init container to fix permissions
      initContainers:
      - name: fix-permissions
        image: busybox
        command:
          - sh
          - -c
          - |
            mkdir -p /app/models /app/cache /tmp
            chmod -R 777 /app/models /app/cache /tmp
        volumeMounts:
        - name: model-cache
          mountPath: /app/models
        - name: cache
          mountPath: /app/cache
        securityContext:
          runAsUser: 0  # Run as root for permission fixes
      
      containers:
      - name: june-tts
        image: ozzuworld/june-tts:latest
        imagePullPolicy: Always
        
        env:
        # OpenVoice Configuration
        - name: OPENVOICE_CHECKPOINTS_V2
          value: "/models/openvoice/checkpoints_v2"
        - name: OPENVOICE_DEVICE
          value: "cuda"
        
        # Optimization flags
        - name: ENABLE_QUANTIZATION
          value: "false"  # Disable for GPU sharing
        - name: PRELOAD_MODELS
          value: "true"
        - name: TTS_CACHE_SIZE
          value: "100"
        
        # CUDA optimizations for shared GPU
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: PYTORCH_CUDA_ALLOC_CONF
          value: "max_split_size_mb:256"
        
        # Keycloak
        - name: KEYCLOAK_URL
          value: "http://june-idp:8080"
        - name: KEYCLOAK_REALM
          value: "allsafe"
        - name: KEYCLOAK_CLIENT_ID
          value: "june-tts"
        - name: KEYCLOAK_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: june-secrets
              key: keycloak-tts-secret
        
        ports:
        - name: http
          containerPort: 8000
        
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
            nvidia.com/gpu: 1  # Request 1 shared GPU slice
          limits:
            cpu: "2"
            memory: "4Gi"
            nvidia.com/gpu: 1  # Limit to 1 shared GPU slice
        
        volumeMounts:
        - name: model-cache
          mountPath: /models
        - name: cache
          mountPath: /tmp/june_tts_cache
        
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 120
          periodSeconds: 10
        
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 180
          periodSeconds: 30
        
        # Run as non-root after init
        securityContext:
          runAsUser: 1001
          runAsGroup: 1001
          fsGroup: 1001
          allowPrivilegeEscalation: false
      
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: tts-model-cache
      - name: cache
        emptyDir:
          sizeLimit: 5Gi

---
# Step 4: Updated STT Deployment with GPU Sharing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: june-stt
  namespace: june
  labels:
    app: june-stt
spec:
  replicas: 1
  selector:
    matchLabels:
      app: june-stt
  template:
    metadata:
      labels:
        app: june-stt
    spec:
      nodeSelector:
        gpu: "true"
      
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      
      # Init container to fix permissions
      initContainers:
      - name: fix-permissions
        image: busybox
        command:
          - sh
          - -c
          - |
            mkdir -p /app/models /app/cache
            chmod -R 777 /app/models /app/cache
        volumeMounts:
        - name: model-cache
          mountPath: /app/models
        - name: cache
          mountPath: /app/cache
        securityContext:
          runAsUser: 0
      
      containers:
      - name: june-stt
        image: nvidia/cuda:12.3.2-cudnn9-runtime-ubuntu22.04
        command: ["python3", "app.py"]
        
        env:
        # Whisper Configuration
        - name: WHISPER_MODEL
          value: "large-v3"
        - name: WHISPER_DEVICE
          value: "cuda"
        - name: WHISPER_COMPUTE_TYPE
          value: "float16"
        - name: WHISPER_CACHE_DIR
          value: "/app/models"
        
        # CUDA optimizations
        - name: CUDA_VISIBLE_DEVICES
          value: "0"
        - name: PYTORCH_CUDA_ALLOC_CONF
          value: "max_split_size_mb:256"
        
        # Keycloak
        - name: KEYCLOAK_URL
          value: "http://june-idp:8080"
        - name: KEYCLOAK_REALM
          value: "allsafe"
        - name: KEYCLOAK_CLIENT_ID
          value: "june-stt"
        - name: KEYCLOAK_CLIENT_SECRET
          valueFrom:
            secretKeyRef:
              name: june-secrets
              key: keycloak-stt-secret
        
        # Orchestrator
        - name: ORCHESTRATOR_URL
          value: "http://june-orchestrator:8080"
        - name: ENABLE_ORCHESTRATOR_NOTIFICATIONS
          value: "true"
        
        ports:
        - name: http
          containerPort: 8000
        
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
            nvidia.com/gpu: 1  # Request 1 shared GPU slice
          limits:
            cpu: "2"
            memory: "4Gi"
            nvidia.com/gpu: 1  # Limit to 1 shared GPU slice
        
        volumeMounts:
        - name: model-cache
          mountPath: /app/models
        - name: cache
          mountPath: /app/cache
        
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 120
          periodSeconds: 10
        
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 180
          periodSeconds: 30
        
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
          fsGroup: 1000
          allowPrivilegeEscalation: false
      
      volumes:
      - name: model-cache
        persistentVolumeClaim:
          claimName: stt-model-cache
      - name: cache
        emptyDir:
          sizeLimit: 5Gi

---
# Step 5: PersistentVolumeClaims for model storage
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: tts-model-cache
  namespace: june
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: standard

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: stt-model-cache
  namespace: june
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi
  storageClassName: standard