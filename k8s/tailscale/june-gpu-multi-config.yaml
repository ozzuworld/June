# Configuration for june-gpu-multi service running on vast.ai
# This file contains environment variables and settings for the external GPU service
# to communicate with Kubernetes services via Tailscale

apiVersion: v1
kind: ConfigMap
metadata:
  name: june-gpu-multi-tailscale-config
  namespace: june-services
  labels:
    app: june-gpu-multi
    deployment: external
data:
  # ============================================
  # TAILSCALE SERVICE ENDPOINTS
  # These endpoints will be available once Tailscale is configured
  # ============================================
  
  # Orchestrator service via Tailscale
  ORCHESTRATOR_URL: "http://june-orchestrator:8080"
  
  # LiveKit service via Tailscale  
  LIVEKIT_WS_URL: "ws://livekit:7880"
  LIVEKIT_HTTP_URL: "http://livekit:7880"
  
  # ============================================
  # SERVICE CONFIGURATION
  # ============================================
  
  # STT Service Configuration
  STT_PORT: "8001"
  WHISPER_MODEL: "base"
  WHISPER_DEVICE: "cuda"
  WHISPER_COMPUTE_TYPE: "float16"
  WHISPER_CACHE_DIR: "/app/models"
  
  # TTS Service Configuration
  TTS_PORT: "8000"
  TTS_MODEL: "tts_models/multilingual/multi-dataset/xtts_v2"
  TTS_CACHE_PATH: "/app/cache"
  TTS_HOME: "/app/models"
  
  # ============================================
  # LIVEKIT CONFIGURATION
  # ============================================
  
  # Room configuration
  ROOM_NAME: "ozzu-main"
  
  # Debug settings
  DEBUG: "false"
  LOG_LEVEL: "INFO"

---
# Secret template for sensitive configuration
# Copy to june-gpu-multi-secrets.yaml and fill in actual values
apiVersion: v1
kind: Secret
metadata:
  name: june-gpu-multi-tailscale-secrets
  namespace: june-services
  labels:
    app: june-gpu-multi
    deployment: external
type: Opaque
stringData:
  # LiveKit credentials (get from existing june-webrtc-config)
  LIVEKIT_API_KEY: "YOUR_LIVEKIT_API_KEY"
  LIVEKIT_API_SECRET: "YOUR_LIVEKIT_API_SECRET"
  
  # Bearer token for webhook authentication
  BEARER_TOKEN: "YOUR_BEARER_TOKEN"
  
  # Optional: Gemini API key if running LLM locally
  GEMINI_API_KEY: "YOUR_GEMINI_API_KEY"