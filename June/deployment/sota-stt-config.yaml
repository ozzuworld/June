# SOTA STT Configuration - Environment Variables for Competitive Voice AI
# Apply these settings for optimal accuracy with English + Latin accent
# Designed to eliminate "Дмитрий" and other false language detections

apiVersion: v1
kind: ConfigMap
metadata:
  name: june-stt-sota-config
  namespace: june-services
  labels:
    app: june-stt
    version: sota-competitive
data:
  # SOTA MODEL CONFIGURATION - Upgraded for competitive accuracy
  WHISPER_MODEL: "large-v3-turbo"              # SOTA: 809M params vs 74M (base)
  WHISPER_DEVICE: "auto"                       # Let it choose best device
  WHISPER_COMPUTE_TYPE: "float16"              # Optimal for GPU
  USE_BATCHED_INFERENCE: "true"                # SOTA: Faster processing
  BATCH_SIZE: "8"                             # Optimal batch size
  
  # SOTA ACCURACY OPTIMIZATION - Force English to prevent language confusion
  DEFAULT_LANGUAGE: "en"                       # SOTA: Always English
  FORCE_LANGUAGE: "true"                      # SOTA: No auto-detection
  ACCENT_OPTIMIZATION: "true"                 # SOTA: Latin accent support
  INITIAL_PROMPT: "English speech with Latin accent. Mathematical terms: square root, calculations, numbers. Technical vocabulary: programming, computer, algorithm, function, variable."
  
  # SOTA STREAMING OPTIMIZATION - Ultra-fast partials
  SOTA_MODE_ENABLED: "true"                   # SOTA: Enable all optimizations
  ULTRA_FAST_PARTIALS: "true"                # SOTA: <150ms first partial goal
  AGGRESSIVE_VAD_TUNING: "true"               # SOTA: More sensitive speech detection
  STT_STREAMING_ENABLED: "true"               # SOTA: Always streaming
  STT_PARTIALS_ENABLED: "true"               # SOTA: Always partials
  STT_CONTINUOUS_PARTIALS: "true"            # SOTA: Continuous streaming
  
  # SOTA TIMING OPTIMIZATION - Competitive response times
  PARTIAL_EMIT_INTERVAL_MS: "200"             # SOTA: 200ms vs 250ms (20% faster)
  PARTIAL_MIN_SPEECH_MS: "200"                # SOTA: 200ms vs 300ms (33% faster)
  SILENCE_TIMEOUT_SEC: "0.8"                  # SOTA: 800ms vs 1200ms (33% faster)
  MAX_UTTERANCE_SEC: "8.0"                    # SOTA: 8s vs 12s (faster turnover)
  MIN_UTTERANCE_SEC: "0.3"                    # SOTA: 300ms vs 500ms (more responsive)
  
  # SILERO VAD CONFIGURATION - Enhanced speech detection
  SILERO_VAD_ENABLED: "true"                  # Keep intelligent detection
  SILERO_VAD_THRESHOLD: "0.5"                 # Balanced sensitivity
  SILERO_MIN_SPEECH_MS: "100"                 # Fast speech start detection
  SILERO_MIN_SILENCE_MS: "100"                # Fast silence detection
  
  # WHISPER QUALITY SETTINGS - Optimized for accuracy
  WHISPER_TEMPERATURE: "0.0"                  # Deterministic (no randomness)
  WHISPER_BEAM_SIZE: "5"                      # Good accuracy/speed balance
  CONDITION_ON_PREVIOUS_TEXT: "false"         # Clean slate for each utterance
  
  # CONNECTIVITY
  ORCHESTRATOR_URL: "https://api.ozzu.world"   # Your orchestrator endpoint
  LIVEKIT_ENABLED: "true"                     # Keep real-time processing
  
---
# SOTA Deployment Patch
apiVersion: apps/v1
kind: Deployment
metadata:
  name: june-stt-sota
  namespace: june-services
spec:
  replicas: 1
  selector:
    matchLabels:
      app: june-stt
      version: sota
  template:
    metadata:
      labels:
        app: june-stt
        version: sota
        optimization: sota-competitive
    spec:
      containers:
      - name: june-stt
        image: your-registry/june-stt:sota-competitive  # Build with SOTA changes
        ports:
        - containerPort: 8001
        envFrom:
        - configMapRef:
            name: june-stt-sota-config
        env:
        # Override with any runtime-specific settings
        - name: LOG_LEVEL
          value: "INFO"
        resources:
          requests:
            memory: "2Gi"      # SOTA: More memory for large-v3-turbo
            cpu: "1000m"
            nvidia.com/gpu: "1" # SOTA: GPU required for large-v3-turbo performance
          limits:
            memory: "4Gi"      # SOTA: Generous limit for model
            cpu: "2000m"
            nvidia.com/gpu: "1"
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8001
          initialDelaySeconds: 120  # SOTA: Longer for model loading
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8001
          initialDelaySeconds: 60
          periodSeconds: 20