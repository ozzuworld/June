# June STT Enhanced - Next Generation Speech-to-Text

**OpenAI API Compatible + Real-time Voice Chat Integration**

Combines the optimization and compatibility of [faster-whisper-server](https://github.com/etalab-ia/faster-whisper-server) with June's sophisticated LiveKit-based real-time voice chat capabilities.

## üéÜ Key Features

### OpenAI API Compatibility
- **Drop-in replacement** for OpenAI's `/v1/audio/transcriptions` endpoint
- **Streaming support** for large file processing
- **Multiple response formats**: JSON, text, verbose JSON
- **Language detection** and translation capabilities

### Real-time Voice Chat
- **LiveKit integration** for multi-participant voice rooms
- **Utterance-level processing** with intelligent speech segmentation
- **Anti-feedback logic** to prevent audio loops
- **Voice Activity Detection (VAD)** for optimal endpointing
- **Live transcription** with sub-second latency

### Advanced Optimizations
- **Dynamic model loading/unloading** for optimal memory usage
- **Batched inference** for high-throughput scenarios
- **GPU acceleration** with automatic fallback to CPU
- **Enhanced noise filtering** and false positive detection
- **Resource management** with configurable limits

## üöÄ Quick Start

### Docker Deployment (Recommended)

```bash
# Build the enhanced image
docker build -f Dockerfile.new -t ozzuworld/june-stt:enhanced .

# Run with GPU support
docker run -d \
  --gpus all \
  -p 8000:8000 \
  -e WHISPER_MODEL=base \
  -e LIVEKIT_ENABLED=true \
  -e LIVEKIT_API_KEY=your_livekit_key \
  -e ORCHESTRATOR_URL=http://your-orchestrator:8080 \
  ozzuworld/june-stt:enhanced

# Run CPU-only
docker run -d \
  -p 8000:8000 \
  -e WHISPER_DEVICE=cpu \
  -e WHISPER_MODEL=base \
  ozzuworld/june-stt:enhanced
```

### Local Development

```bash
# Install dependencies
pip install -r requirements_enhanced.txt

# Set environment variables
export WHISPER_MODEL=base
export LIVEKIT_ENABLED=true
export LIVEKIT_API_KEY=your_key
export ORCHESTRATOR_URL=http://localhost:8080

# Run the enhanced service
python main_enhanced.py
```

## üîå API Endpoints

### OpenAI-Compatible Transcription

#### `POST /v1/audio/transcriptions`
Transcribe audio files with OpenAI API compatibility.

**cURL Example:**
```bash
curl -X POST "http://localhost:8000/v1/audio/transcriptions" \
  -F "file=@audio.mp3" \
  -F "model=base" \
  -F "language=en" \
  -F "response_format=json"
```

**Python Example:**
```python
import openai

# Configure to use June STT Enhanced
client = openai.OpenAI(
    api_key="not-needed",
    base_url="http://localhost:8000/v1/"
)

with open("audio.wav", "rb") as audio_file:
    transcript = client.audio.transcriptions.create(
        model="base",
        file=audio_file,
        language="en"
    )
    print(transcript.text)
```

### Monitoring & Health

#### `GET /healthz`
Comprehensive health check with component status.

#### `GET /stats`
Detailed processing statistics and participant information.

#### `GET /`
Service information and feature overview.

## üîß Configuration

### Core Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `WHISPER_MODEL` | `base` | Whisper model (tiny/base/small/medium/large) |
| `WHISPER_DEVICE` | `auto` | Device (auto/cuda/cpu) |
| `USE_BATCHED_INFERENCE` | `true` | Enable batched processing |
| `BATCH_SIZE` | `8` | Batch size for processing |
| `DYNAMIC_MODEL_LOADING` | `true` | Auto load/unload models |

### LiveKit Integration

| Variable | Default | Description |
|----------|---------|-------------|
| `LIVEKIT_ENABLED` | `true` | Enable real-time voice chat |
| `LIVEKIT_WS_URL` | `ws://livekit:80` | LiveKit server URL |
| `LIVEKIT_API_KEY` | `devkey` | LiveKit API key |
| `LIVEKIT_ROOM_NAME` | `ozzu-main` | Room name for voice chat |

### Speech Processing

| Variable | Default | Description |
|----------|---------|-------------|
| `START_THRESHOLD_RMS` | `0.012` | RMS threshold to start utterance |
| `CONTINUE_THRESHOLD_RMS` | `0.006` | RMS threshold to continue |
| `END_SILENCE_SEC` | `0.8` | Silence duration to end utterance |
| `MIN_UTTERANCE_SEC` | `0.8` | Minimum utterance length |
| `MAX_UTTERANCE_SEC` | `6.0` | Maximum utterance length |

### Integration Settings

| Variable | Default | Description |
|----------|---------|-------------|
| `ORCHESTRATOR_URL` | `http://orchestrator:8080` | June orchestrator endpoint |
| `KEYCLOAK_ENABLED` | `false` | Enable Keycloak authentication |
| `VAD_ENABLED` | `false` | Enable Voice Activity Detection |

## üé• Architecture

### Dual Processing Modes

**File Processing Mode (OpenAI Compatible)**
```
File Upload ‚Üí Validation ‚Üí Whisper Processing ‚Üí Response
     ‚îÇ              ‚îÇ               ‚îÇ
     ‚îÇ              ‚îÇ               ‚Üí Streaming Support
     ‚îÇ              ‚Üí Multi-format Support
     ‚Üí OpenAI API Format
```

**Real-time Voice Chat Mode**
```
LiveKit Room ‚Üí Audio Frames ‚Üí Utterance Assembly ‚Üí Transcription ‚Üí Orchestrator
     ‚îÇ              ‚îÇ                ‚îÇ                ‚îÇ
     ‚îÇ              ‚îÇ                ‚îÇ                ‚Üí Webhook Notification
     ‚îÇ              ‚îÇ                ‚Üí VAD Processing
     ‚îÇ              ‚Üí Anti-feedback Filter
     ‚Üí Multi-participant Support
```

### Service Components

1. **Enhanced Whisper Service**: Dynamic model loading with optimization
2. **LiveKit Manager**: Real-time audio processing and room management
3. **Orchestrator Client**: Integration with June platform
4. **OpenAI API Layer**: Full compatibility with existing applications
5. **Configuration Manager**: Centralized settings with validation

## üìà Performance

### Model Comparison

| Model | Size | GPU Memory | CPU Cores | Speed | Quality |
|-------|------|------------|-----------|-------|----------|
| `tiny` | 39 MB | 1 GB | 2+ | Fastest | Basic |
| `base` | 74 MB | 1 GB | 4+ | Fast | Good |
| `small` | 244 MB | 2 GB | 6+ | Medium | Better |
| `medium` | 769 MB | 3 GB | 8+ | Slow | High |
| `large` | 1550 MB | 6 GB | 12+ | Slowest | Best |

### Optimization Features

- **Batched Processing**: Up to 5x throughput improvement
- **Dynamic Loading**: 50-80% memory savings during idle periods
- **GPU Acceleration**: 10-20x faster than CPU processing
- **Utterance Segmentation**: Reduces latency for voice chat
- **Enhanced VAD**: Eliminates silent periods before processing

## üîç Monitoring

### Health Checks

```bash
# Quick health check
curl http://localhost:8000/healthz

# Detailed statistics
curl http://localhost:8000/stats
```

### Logging

The service provides structured logging with multiple levels:

```python
# Set log level
export LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR
```

### Metrics

- Processing time per request
- Model usage statistics
- Active participant counts
- Memory and GPU utilization
- Error rates and types

## üîí Security

### Authentication Options

- **Keycloak Integration**: JWT token validation
- **Service Tokens**: Internal service authentication
- **API Keys**: Simple key-based access

### File Security

- Temporary file isolation
- Size limits (100MB default)
- Format validation
- Automatic cleanup

## üêõ Troubleshooting

### Common Issues

**1. Model Loading Errors**
```bash
# Check GPU availability
nvidia-smi

# Try CPU fallback
export WHISPER_DEVICE=cpu
```

**2. LiveKit Connection Issues**
```bash
# Check LiveKit server status
curl http://livekit-server/healthz

# Verify API credentials
echo $LIVEKIT_API_KEY
```

**3. Memory Issues**
```bash
# Enable dynamic loading
export DYNAMIC_MODEL_LOADING=true

# Use smaller model
export WHISPER_MODEL=base
```

**4. Audio Processing Issues**
```bash
# Check audio format support
ffmpeg -formats | grep wav

# Enable detailed logging
export LOG_LEVEL=DEBUG
```

### Performance Tuning

**For High Throughput:**
```bash
export USE_BATCHED_INFERENCE=true
export BATCH_SIZE=16
export VAD_ENABLED=true
```

**For Low Latency:**
```bash
export USE_BATCHED_INFERENCE=false
export DYNAMIC_MODEL_LOADING=false
export WHISPER_MODEL=base
```

**For Memory Efficiency:**
```bash
export DYNAMIC_MODEL_LOADING=true
export MODEL_UNLOAD_TIMEOUT=60
export WHISPER_MODEL=base
```

## üöÄ Deployment

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: june-stt-enhanced
spec:
  replicas: 2
  selector:
    matchLabels:
      app: june-stt-enhanced
  template:
    metadata:
      labels:
        app: june-stt-enhanced
    spec:
      containers:
      - name: june-stt-enhanced
        image: ozzuworld/june-stt:enhanced
        ports:
        - containerPort: 8000
        env:
        - name: WHISPER_MODEL
          value: "base"
        - name: LIVEKIT_ENABLED
          value: "true"
        - name: USE_BATCHED_INFERENCE
          value: "true"
        resources:
          requests:
            memory: "4Gi"
            cpu: "1"
            nvidia.com/gpu: "1"
          limits:
            memory: "8Gi"
            cpu: "2"
            nvidia.com/gpu: "1"
```

### Helm Chart Integration

Update your `helm/june-platform/values.yaml`:

```yaml
stt:
  enabled: true
  replicas: 1
  image:
    repository: ozzuworld/june-stt
    tag: enhanced
  features:
    openaiCompatible: true
    livekitIntegration: true
    dynamicLoading: true
    batchedInference: true
```

## üìö Migration Guide

### From Original June STT

1. **Backup current configuration**
2. **Update Docker image** to use enhanced version
3. **Verify environment variables** (most remain compatible)
4. **Test both file processing and real-time features**
5. **Update orchestrator integration** if needed

### From Other Whisper Services

1. **Update API endpoints** to use `/v1/audio/transcriptions`
2. **Configure model and device settings**
3. **Enable features** as needed (batched inference, dynamic loading)
4. **Test with existing audio files**

## üìù API Reference

### Complete OpenAI Compatibility

This service implements the full OpenAI Audio API specification:

- [OpenAI Audio API Documentation](https://platform.openai.com/docs/api-reference/audio)
- All parameters and response formats supported
- Streaming and non-streaming modes
- Multiple audio format support

### Additional June-Specific Endpoints

- `GET /stats` - Processing statistics
- `GET /model/info` - Model information
- `POST /model/reload` - Force model reload
- `GET /livekit/status` - LiveKit connection status

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Update documentation
6. Submit a pull request

## üìú License

This enhanced version maintains compatibility with both:
- June platform licensing
- faster-whisper-server MIT license

---

**June STT Enhanced** - Bringing together the best of OpenAI compatibility and real-time voice chat capabilities.
