#!/usr/bin/env python3
"""
June STT Service - Whisper-Streaming Real-Time Implementation
Real-time Speech-to-Text with whisper-streaming (UFAL)
Achieves ~3.3s latency vs 15s+ with WhisperX batching
"""
import asyncio
import logging
import uuid
import os
import time
from datetime import datetime
from contextlib import asynccontextmanager
from typing import Optional, Dict

import numpy as np
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from livekit import rtc
from scipy import signal
import httpx

from config import config
from whisper_streaming_service import whisper_streaming_service
from livekit_token import connect_room_as_subscriber
from streaming_utils import streaming_metrics

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("june-stt-streaming")

# Global state
room: Optional[rtc.Room] = None
room_connected: bool = False
orchestrator_available: bool = False
processed_transcripts = 0

# Constants
SAMPLE_RATE = 16000
MIN_CHUNK_SIZE = float(os.getenv("MIN_CHUNK_SIZE", "1.0"))  # Process every 1 second
EXCLUDE_PARTICIPANTS = {"june-tts", "june-stt", "tts", "stt"}

logger.info(f"âš¡ Whisper-Streaming config: MIN_CHUNK={MIN_CHUNK_SIZE}s")


async def _check_orchestrator_health() -> bool:
    """Check orchestrator availability"""
    if not config.ORCHESTRATOR_URL:
        return False
    try:
        async with httpx.AsyncClient(timeout=2.0) as client:
            r = await client.get(f"{config.ORCHESTRATOR_URL}/healthz")
            return r.status_code == 200
    except Exception:
        return False


async def _notify_orchestrator(user_id: str, text: str, language: Optional[str]):
    """Send confirmed transcript to orchestrator"""
    global orchestrator_available, processed_transcripts
    
    if not config.ORCHESTRATOR_URL or not text.strip():
        return

    payload = {
        "transcript_id": str(uuid.uuid4()),
        "user_id": user_id,
        "participant": user_id,
        "event": "transcript",
        "text": text.strip(),
        "language": language or "en",
        "timestamp": datetime.utcnow().isoformat(),
        "room_name": "ozzu-main",
        "partial": False,  # whisper-streaming only sends confirmed outputs
    }

    try:
        async with httpx.AsyncClient(timeout=4.0) as client:
            r = await client.post(f"{config.ORCHESTRATOR_URL}/api/webhooks/stt", json=payload)
            orchestrator_available = r.status_code in (200, 429)
            if r.status_code == 200:
                processed_transcripts += 1
                streaming_metrics.record_final()
                logger.info(f"âœ… Transcript sent: '{text[:60]}...' [{len(text)} chars]")
    except Exception as e:
        logger.warning(f"Orchestrator notify failed: {e}")
        orchestrator_available = False


_first_frame_seen = set()


def _frame_to_float32_mono(frame: rtc.AudioFrame):
    """Convert LiveKit audio frame to float32 mono"""
    sr = frame.sample_rate
    ch = frame.num_channels
    buf = memoryview(frame.data)
    
    try:
        arr = np.frombuffer(buf, dtype=np.int16).astype(np.float32) / 32768.0
    except Exception:
        arr = np.frombuffer(buf, dtype=np.float32)
    
    if ch and ch > 1:
        try:
            arr = arr.reshape(-1, ch).mean(axis=1)
        except Exception:
            frames = arr[: (len(arr) // ch) * ch]
            arr = frames.reshape(-1, ch).mean(axis=1)
    
    return np.nan_to_num(arr, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32), sr


def _resample_to_16k_mono(pcm: np.ndarray, sr: int) -> np.ndarray:
    """Resample audio to 16kHz"""
    if sr == SAMPLE_RATE:
        return pcm
    gcd = np.gcd(sr, SAMPLE_RATE)
    up = SAMPLE_RATE // gcd
    down = sr // gcd
    out = signal.resample_poly(pcm, up, down).astype(np.float32)
    return np.nan_to_num(out, nan=0.0, posinf=0.0, neginf=0.0)


async def _on_audio_frame(pid: str, frame: rtc.AudioFrame):
    """
    Handle incoming audio frame - stream to whisper-streaming processor
    This is the core real-time processing function
    """
    if pid in EXCLUDE_PARTICIPANTS:
        return
    
    try:
        # Convert and resample to 16kHz mono float32
        pcm, sr = _frame_to_float32_mono(frame)
        pcm16k = _resample_to_16k_mono(pcm, sr)
        
        if pid not in _first_frame_seen:
            logger.info(f"ðŸŽ¤ First frame: {pid} | in_sr={sr} out_sr=16000 samples={len(pcm16k)}")
            _first_frame_seen.add(pid)
        
        # Feed to whisper-streaming processor
        # This uses LocalAgreement-2 policy for low latency
        confirmed_text = await whisper_streaming_service.process_audio_chunk(pid, pcm16k)
        
        # If we got confirmed text, send to orchestrator
        if confirmed_text:
            logger.info(f"ðŸŽ¯ Confirmed: {pid} -> '{confirmed_text[:60]}...'")
            await _notify_orchestrator(pid, confirmed_text, "en")
        
    except Exception as e:
        logger.error(f"Audio frame error {pid}: {e}", exc_info=False)


def setup_room_callbacks(room: rtc.Room):
    """Setup LiveKit room event handlers"""
    
    @room.on("participant_connected")
    def _p_join(p):
        logger.info(f"ðŸ‘¤ Participant joined: {p.identity} (sid={getattr(p, 'sid', 'n/a')})")
        if p.identity not in EXCLUDE_PARTICIPANTS:
            # Processor will be created on first audio frame
            pass

    @room.on("track_published")
    def _track_pub(pub, participant):
        try:
            kind = getattr(pub, "kind", None) or getattr(pub, "track", {}).get("kind")
        except Exception:
            kind = "unknown"
        logger.info(f"ðŸ“¢ Track published: {participant.identity} | kind={kind}")

    @room.on("participant_disconnected")
    async def _p_leave(p):
        pid = p.identity
        logger.info(f"ðŸ‘‹ Participant left: {pid}")
        
        # Finish any pending utterance
        final_text = await whisper_streaming_service.finish_utterance(pid)
        if final_text:
            logger.info(f"ðŸ“ Final transcript: {pid} -> '{final_text[:60]}...'")
            await _notify_orchestrator(pid, final_text, "en")
        
        # Clean up processor
        whisper_streaming_service.remove_processor(pid)

    @room.on("track_subscribed")
    def _track_sub(track: rtc.Track, pub, participant):
        logger.info(f"ðŸŽ§ Track subscribed: {participant.identity} | kind={track.kind}")
        
        if track.kind != rtc.TrackKind.KIND_AUDIO:
            return
        
        pid = participant.identity or participant.sid
        if pid in EXCLUDE_PARTICIPANTS:
            logger.info(f"â­ï¸  Skipping excluded participant: {pid}")
            return
        
        stream = rtc.AudioStream(track)
        first_frame = {"seen": False}
        
        async def consume():
            logger.info(f"ðŸ”Š Consuming audio: {pid} | track_sid={getattr(track, 'sid', 'n/a')}")
            async for event in stream:
                if not first_frame["seen"]:
                    logger.info(f"â–¶ï¸  First frame received: {pid} | sr={event.frame.sample_rate} ch={event.frame.num_channels}")
                    first_frame["seen"] = True
                await _on_audio_frame(pid, event.frame)
        
        asyncio.create_task(consume())


async def join_livekit_room():
    """Connect to LiveKit room"""
    global room, room_connected, orchestrator_available
    
    if not config.LIVEKIT_ENABLED:
        logger.info("LiveKit disabled")
        return
        
    try:
        room = rtc.Room()
        setup_room_callbacks(room)
        await connect_room_as_subscriber(room, "june-stt")
        room_connected = True
        logger.info("âœ… STT connected to LiveKit")
        
        orchestrator_available = await _check_orchestrator_health()
        logger.info(f"âœ… Orchestrator: {'available' if orchestrator_available else 'unavailable'}")
        
    except Exception as e:
        logger.error(f"âŒ LiveKit connection failed: {e}")
        room_connected = False


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan manager"""
    logger.info("="*80)
    logger.info("ðŸš€ June STT Service - Whisper-Streaming Edition")
    logger.info("="*80)
    
    try:
        await whisper_streaming_service.initialize()
        logger.info("âœ… Whisper-Streaming ready")
    except Exception as e:
        logger.error(f"âŒ Service init failed: {e}")
        raise
        
    await join_livekit_room()
    
    if room_connected:
        logger.info("âœ… Real-time streaming active")
    else:
        logger.info("âš ï¸  Running in API-only mode (no LiveKit)")
        
    logger.info("="*80)
        
    yield
    
    # Cleanup
    if room and room_connected:
        try:
            await room.disconnect()
        except Exception:
            pass
    
    await whisper_streaming_service.cleanup()


app = FastAPI(
    title="June STT - Whisper-Streaming",
    version="9.0.0-whisper-streaming",
    description="Real-time Speech-to-Text with whisper-streaming (~3.3s latency)",
    lifespan=lifespan,
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.get("/healthz")
async def health():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "version": "9.0.0-whisper-streaming",
        "framework": "whisper-streaming (UFAL)",
        "components": {
            "whisper_streaming_ready": whisper_streaming_service.is_model_ready(),
            "livekit_connected": room_connected,
            "orchestrator_available": orchestrator_available,
        },
        "features": {
            "real_time_streaming": True,
            "vad": "silero",
            "policy": "LocalAgreement-2",
            "expected_latency_sec": 3.3,
        }
    }


@app.get("/")
async def root():
    """Root endpoint with service info"""
    model_info = whisper_streaming_service.get_model_info()
    
    return {
        "service": "june-stt-streaming",
        "version": "9.0.0-whisper-streaming",
        "description": "Real-time Speech-to-Text with whisper-streaming",
        "latency_improvement": "15s -> 3.3s (78% reduction)",
        "model": model_info,
        "status": {
            "active_processors": model_info.get("active_processors", 0),
            "processed_transcripts": processed_transcripts,
            "orchestrator_reachable": orchestrator_available,
        },
        "stats": streaming_metrics.get_stats(),
    }


@app.get("/stats")
async def stats():
    """Detailed statistics endpoint"""
    return {
        "status": "success",
        "version": "9.0.0-whisper-streaming",
        "connectivity": {
            "livekit_connected": room_connected,
            "orchestrator_available": orchestrator_available,
        },
        "model_info": whisper_streaming_service.get_model_info(),
        "global_stats": {
            "processed_transcripts": processed_transcripts,
            "active_processors": len(whisper_streaming_service.processors),
        },
        "metrics": streaming_metrics.get_stats(),
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=config.PORT)
