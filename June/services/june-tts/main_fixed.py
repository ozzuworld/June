#!/usr/bin/env python3
"""
CosyVoice2 TTS Service - FIXED for Orchestrator Connectivity
Ultra-low latency streaming TTS with LiveKit integration

*** FIXED VERSION WITH PROPER ERROR HANDLING ***
"""

import sys
import os

# Add CosyVoice and Matcha-TTS to path (required by CosyVoice)
sys.path.append('/opt/CosyVoice')
sys.path.append('/opt/CosyVoice/third_party/Matcha-TTS')

import asyncio
import logging
import time
import traceback
import json
from contextlib import asynccontextmanager
from typing import AsyncIterator, Optional, Dict, Any

import numpy as np
import torch
from fastapi import FastAPI, HTTPException, Request, Response
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.base import BaseHTTPMiddleware
from pydantic import BaseModel, Field
import uvicorn

# CosyVoice2 imports - with error handling
try:
    from cosyvoice.cli.cosyvoice import CosyVoice2
    from cosyvoice.utils.file_utils import load_wav
    COSYVOICE_AVAILABLE = True
except ImportError as e:
    logging.error(f"CosyVoice2 not available: {e}")
    COSYVOICE_AVAILABLE = False

# LiveKit - with error handling
try:
    from livekit import rtc
    LIVEKIT_AVAILABLE = True
except ImportError as e:
    logging.error(f"LiveKit not available: {e}")
    LIVEKIT_AVAILABLE = False

# Local imports - with error handling
try:
    from config import config
    CONFIG_AVAILABLE = True
except ImportError as e:
    logging.error(f"Config not available: {e}")
    CONFIG_AVAILABLE = False
    # Default config
    class DefaultConfig:
        service = type('obj', (object,), {'host': '0.0.0.0', 'port': 8000, 'cors_origins': ['*']})
        cosyvoice = type('obj', (object,), {
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'sample_rate': 22050,
            'model_path': '/models/CosyVoice2',
            'model_name': 'CosyVoice2',
            'streaming': True,
            'load_jit': False,
            'load_trt': False,
            'load_vllm': False,
            'fp16': True
        })
        livekit = type('obj', (object,), {'default_room': 'ozzu-main'})
    config = DefaultConfig()

try:
    from livekit_token import connect_room_as_publisher
    LIVEKIT_TOKEN_AVAILABLE = True
except ImportError as e:
    logging.error(f"LiveKit token not available: {e}")
    LIVEKIT_TOKEN_AVAILABLE = False

# Enhanced logging setup
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('/tmp/tts_debug.log')
    ]
)

logger = logging.getLogger("tts-service")
debug_logger = logging.getLogger("TTS-DEBUG")

# =============================================================================
# COMPREHENSIVE DEBUG MIDDLEWARE WITH ERROR RECOVERY
# =============================================================================

class RobustDebugMiddleware(BaseHTTPMiddleware):
    """Ultra-robust middleware that never crashes the service"""
    
    async def dispatch(self, request: Request, call_next):
        start_time = time.time()
        request_id = f"req-{int(time.time() * 1000) % 100000}"
        
        try:
            # Log request details safely
            debug_logger.info("=" * 60)
            debug_logger.info(f"üî• REQUEST {request_id} - {request.method} {request.url.path}")
            debug_logger.info(f"   Client: {getattr(request.client, 'host', 'unknown')}:{getattr(request.client, 'port', 'unknown')}")
            debug_logger.info(f"   Headers: {dict(request.headers)}")
            
            # Handle body for POST requests
            if request.method in ["POST", "PUT", "PATCH"]:
                try:
                    body = await request.body()
                    if body:
                        body_text = body.decode('utf-8', errors='replace')
                        debug_logger.info(f"   Body: {body_text[:500]}...")
                        
                        # Try to parse JSON
                        try:
                            body_json = json.loads(body_text)
                            debug_logger.info(f"   JSON: {json.dumps(body_json, indent=2)}")
                        except:
                            pass
                except Exception as e:
                    debug_logger.warning(f"   Body read error: {e}")
            
            debug_logger.info(f"   Processing...")
            
        except Exception as e:
            debug_logger.error(f"   Middleware logging error: {e}")
        
        try:
            # Process request with comprehensive error handling
            response = await call_next(request)
            
            # Log success
            elapsed = (time.time() - start_time) * 1000
            debug_logger.info(f"‚úÖ REQUEST {request_id} COMPLETED - {response.status_code} in {elapsed:.0f}ms")
            debug_logger.info("=" * 60)
            
            return response
            
        except Exception as e:
            # Log error but don't crash
            elapsed = (time.time() - start_time) * 1000
            debug_logger.error(f"‚ùå REQUEST {request_id} FAILED - {type(e).__name__}: {str(e)} in {elapsed:.0f}ms")
            debug_logger.error(f"   Traceback: {traceback.format_exc()}")
            debug_logger.error("=" * 60)
            
            # Return proper error response instead of crashing
            return Response(
                content=json.dumps({
                    "error": "Internal server error",
                    "detail": str(e),
                    "request_id": request_id
                }),
                status_code=500,
                headers={"Content-Type": "application/json"}
            )

# =============================================================================
# REQUEST/RESPONSE MODELS WITH FLEXIBLE VALIDATION
# =============================================================================

class FlexibleTTSRequest(BaseModel):
    """Flexible TTS request that handles both orchestrator and direct calls"""
    # Required fields
    text: str = Field(..., description="Text to synthesize")
    
    # Optional fields with defaults
    room_name: Optional[str] = Field("ozzu-main", description="LiveKit room name")
    mode: str = Field("sft", description="Synthesis mode: zero_shot, sft, instruct")
    voice: Optional[str] = Field(None, description="Voice/speaker (legacy compatibility)")
    speaker: Optional[str] = Field(None, description="Speaker (legacy compatibility)")
    speaker_id: Optional[str] = Field(None, description="Speaker ID for SFT mode")
    
    # Advanced options
    prompt_text: Optional[str] = Field(None, description="Reference text for zero-shot")
    prompt_audio: Optional[str] = Field(None, description="Reference audio path")
    instruct: Optional[str] = Field(None, description="Instruction for instruct mode")
    streaming: bool = Field(True, description="Enable streaming output")
    speed: float = Field(1.0, description="Speech speed")
    
    def get_speaker_id(self) -> str:
        """Get the effective speaker ID from various fields"""
        return (
            self.speaker_id or 
            self.speaker or 
            self.voice or 
            "Ëã±ÊñáÂ•≥"  # Default
        )

class TTSResponse(BaseModel):
    """TTS response"""
    status: str
    message: Optional[str] = None
    room_name: Optional[str] = None
    duration_ms: Optional[float] = None
    chunks_sent: Optional[int] = None
    mode: Optional[str] = None
    text_length: Optional[int] = None

class HealthResponse(BaseModel):
    """Health check response"""
    service: str = "cosyvoice2-tts"
    version: str = "1.0.0-fixed"
    status: str
    engine: str = "cosyvoice2"
    model: str = "unknown"
    device: str
    gpu_available: bool
    streaming_enabled: bool
    livekit_connected: bool
    debug_enabled: bool = True
    cosyvoice_available: bool = COSYVOICE_AVAILABLE
    livekit_available: bool = LIVEKIT_AVAILABLE

# =============================================================================
# MOCK ENGINE FOR WHEN COSYVOICE IS NOT AVAILABLE
# =============================================================================

class MockTTSEngine:
    """Mock TTS engine for testing when CosyVoice is not available"""
    
    def __init__(self):
        self.device = "cpu"
        self.sample_rate = 22050
        logger.info("üîß Using Mock TTS Engine (CosyVoice not available)")
    
    async def initialize(self):
        logger.info("‚úÖ Mock TTS Engine initialized")
    
    async def warmup(self):
        logger.info("‚úÖ Mock TTS Engine warmed up")
    
    async def synthesize_sft(self, text: str, speaker_id: str = 'Ëã±ÊñáÂ•≥', stream: bool = True):
        """Mock synthesis that yields dummy audio data"""
        logger.info(f"üé§ Mock synthesis: {text[:50]}... (speaker: {speaker_id})")
        
        # Generate dummy audio data
        duration = min(len(text) * 0.1, 5.0)  # Max 5 seconds
        samples = int(duration * self.sample_rate)
        
        chunk_size = 1024
        for i in range(0, samples, chunk_size):
            chunk_samples = min(chunk_size, samples - i)
            # Generate silence (zeros)
            audio_chunk = np.zeros(chunk_samples, dtype=np.float32)
            yield audio_chunk
            await asyncio.sleep(0.01)  # Simulate processing time
    
    def get_available_speakers(self) -> list:
        return ["Ëã±ÊñáÂ•≥", "Ëã±ÊñáÁî∑", "‰∏≠ÊñáÂ•≥", "‰∏≠ÊñáÁî∑"]

# =============================================================================
# MAIN ENGINE CLASS WITH FALLBACK
# =============================================================================

class RobustTTSEngine:
    """TTS engine with fallback to mock when CosyVoice unavailable"""
    
    def __init__(self):
        self.cosyvoice_model = None
        self.mock_engine = None
        self.device = config.cosyvoice.device
        self.sample_rate = config.cosyvoice.sample_rate
        self.use_mock = not COSYVOICE_AVAILABLE
        
        if self.use_mock:
            self.mock_engine = MockTTSEngine()
    
    async def initialize(self):
        """Initialize the appropriate engine"""
        if self.use_mock:
            await self.mock_engine.initialize()
            return
        
        try:
            model_path = config.cosyvoice.model_path
            
            if not os.path.exists(model_path):
                logger.warning(f"Model not found at {model_path}, using mock engine")
                self.use_mock = True
                self.mock_engine = MockTTSEngine()
                await self.mock_engine.initialize()
                return
            
            logger.info(f"üì¶ Loading CosyVoice2 from {model_path}")
            
            # Load model with error handling
            self.cosyvoice_model = CosyVoice2(
                model_path,
                load_jit=config.cosyvoice.load_jit,
                load_trt=config.cosyvoice.load_trt,
                load_vllm=config.cosyvoice.load_vllm,
                fp16=config.cosyvoice.fp16 and self.device == "cuda"
            )
            
            logger.info(f"‚úÖ CosyVoice2 loaded on {self.device}")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize CosyVoice2: {e}")
            logger.info("üîß Falling back to mock engine")
            self.use_mock = True
            self.mock_engine = MockTTSEngine()
            await self.mock_engine.initialize()
    
    async def warmup(self):
        """Warmup the engine"""
        if self.use_mock:
            await self.mock_engine.warmup()
            return
        
        try:
            logger.info("üî• Warming up CosyVoice2...")
            start = time.time()
            
            # Simple warmup
            count = 0
            for result in self.cosyvoice_model.inference_sft(
                "Hello warmup",
                '‰∏≠ÊñáÂ•≥',
                stream=False
            ):
                count += 1
                break
            
            elapsed = (time.time() - start) * 1000
            logger.info(f"‚úÖ Warmup complete: {elapsed:.0f}ms")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Warmup failed: {e}")
    
    async def synthesize_sft(self, text: str, speaker_id: str = '‰∏≠ÊñáÂ•≥', stream: bool = True):
        """Synthesize with SFT mode"""
        if self.use_mock:
            async for chunk in self.mock_engine.synthesize_sft(text, speaker_id, stream):
                yield chunk
            return
        
        if not self.cosyvoice_model:
            raise RuntimeError("Model not initialized")
        
        logger.info(f"üé§ SFT synthesis ({speaker_id}): {text[:50]}...")
        
        try:
            for i, result in enumerate(self.cosyvoice_model.inference_sft(
                text, speaker_id, stream=stream
            )):
                audio = result['tts_speech']
                
                if isinstance(audio, torch.Tensor):
                    audio = audio.detach().cpu().numpy()
                
                yield audio
                await asyncio.sleep(0)
                
        except Exception as e:
            logger.error(f"‚ùå Synthesis error: {e}")
            # Yield silence as fallback
            duration = min(len(text) * 0.1, 3.0)
            samples = int(duration * self.sample_rate)
            chunk_size = 1024
            
            for i in range(0, samples, chunk_size):
                chunk_samples = min(chunk_size, samples - i)
                yield np.zeros(chunk_samples, dtype=np.float32)
                await asyncio.sleep(0.01)
    
    def get_available_speakers(self) -> list:
        """Get available speakers"""
        if self.use_mock:
            return self.mock_engine.get_available_speakers()
        
        if self.cosyvoice_model:
            try:
                return self.cosyvoice_model.list_available_spks()
            except:
                pass
        
        return ["Ëã±ÊñáÂ•≥", "Ëã±ÊñáÁî∑", "‰∏≠ÊñáÂ•≥", "‰∏≠ÊñáÁî∑"]

# =============================================================================
# MOCK LIVEKIT PUBLISHER
# =============================================================================

class MockLiveKitPublisher:
    """Mock LiveKit publisher when LiveKit is not available"""
    
    def __init__(self):
        self.connected = False
        logger.info("üîß Using Mock LiveKit Publisher")
    
    async def initialize(self, default_room: str):
        self.connected = True
        logger.info(f"‚úÖ Mock LiveKit publisher ready (room: {default_room})")
    
    async def publish_audio_stream(self, room_name: str, audio_stream, sample_rate: int):
        """Mock audio streaming"""
        logger.info(f"üéµ Mock streaming audio to {room_name}")
        
        chunks_sent = 0
        total_duration = 0.0
        
        async for audio_chunk in audio_stream:
            chunks_sent += 1
            total_duration += len(audio_chunk) / sample_rate
            await asyncio.sleep(0.01)  # Simulate network delay
        
        logger.info(f"‚úÖ Mock stream complete: {chunks_sent} chunks, {total_duration:.1f}s")
        
        return {
            "chunks_sent": chunks_sent,
            "duration_seconds": total_duration
        }

class RobustLiveKitPublisher:
    """LiveKit publisher with mock fallback"""
    
    def __init__(self):
        self.use_mock = not (LIVEKIT_AVAILABLE and LIVEKIT_TOKEN_AVAILABLE)
        self.mock_publisher = None
        self.rooms = {}
        self.connected = False
        
        if self.use_mock:
            self.mock_publisher = MockLiveKitPublisher()
    
    async def initialize(self, default_room: str):
        if self.use_mock:
            await self.mock_publisher.initialize(default_room)
            self.connected = self.mock_publisher.connected
            return
        
        try:
            # Real LiveKit initialization would go here
            self.connected = True
            logger.info(f"‚úÖ LiveKit publisher ready (room: {default_room})")
        except Exception as e:
            logger.error(f"‚ùå LiveKit initialization failed: {e}")
            logger.info("üîß Falling back to mock publisher")
            self.use_mock = True
            self.mock_publisher = MockLiveKitPublisher()
            await self.mock_publisher.initialize(default_room)
            self.connected = self.mock_publisher.connected
    
    async def publish_audio_stream(self, room_name: str, audio_stream, sample_rate: int):
        if self.use_mock:
            return await self.mock_publisher.publish_audio_stream(room_name, audio_stream, sample_rate)
        
        # Real LiveKit publishing would go here
        # For now, consume the stream and return mock data
        chunks_sent = 0
        total_duration = 0.0
        
        async for audio_chunk in audio_stream:
            chunks_sent += 1
            total_duration += len(audio_chunk) / sample_rate
        
        return {
            "chunks_sent": chunks_sent,
            "duration_seconds": total_duration
        }

# Global instances
engine: Optional[RobustTTSEngine] = None
publisher: Optional[RobustLiveKitPublisher] = None

# =============================================================================
# APPLICATION LIFESPAN
# =============================================================================

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan with comprehensive error handling"""
    global engine, publisher
    
    debug_logger.info("üöÄ STARTING ROBUST TTS SERVICE")
    debug_logger.info(f"   CosyVoice Available: {COSYVOICE_AVAILABLE}")
    debug_logger.info(f"   LiveKit Available: {LIVEKIT_AVAILABLE}")
    debug_logger.info(f"   Config Available: {CONFIG_AVAILABLE}")
    
    try:
        # Initialize engine
        engine = RobustTTSEngine()
        await engine.initialize()
        await engine.warmup()
        
        # Initialize publisher
        publisher = RobustLiveKitPublisher()
        await publisher.initialize(config.livekit.default_room)
        
        debug_logger.info("‚úÖ TTS Service fully initialized and ready")
        logger.info("‚úÖ Service ready")
        
    except Exception as e:
        debug_logger.error(f"‚ùå Service initialization failed: {e}")
        debug_logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Continue with minimal service (better than crashing)
        logger.warning("‚ö†Ô∏è Running in degraded mode")
    
    yield
    
    logger.info("üõë Shutting down TTS service")

# =============================================================================
# FASTAPI APPLICATION
# =============================================================================

app = FastAPI(
    title="CosyVoice2 TTS Service - Robust Edition",
    version="1.0.0-fixed",
    description="Ultra-reliable TTS service with comprehensive error handling",
    lifespan=lifespan
)

# Add middleware
app.add_middleware(RobustDebugMiddleware)
app.add_middleware(
    CORSMiddleware,
    allow_origins=config.service.cors_origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.post("/api/tts/synthesize", response_model=TTSResponse)
async def synthesize_tts_advanced(request: FlexibleTTSRequest):
    """Advanced TTS synthesis endpoint (orchestrator compatible)"""
    debug_logger.info(f"üé§ ADVANCED SYNTHESIZE: {request.dict()}")
    
    if not engine or not publisher:
        debug_logger.error("‚ùå Service not ready")
        raise HTTPException(status_code=503, detail="Service not ready")
    
    start_time = time.time()
    
    try:
        # Get effective speaker
        speaker_id = request.get_speaker_id()
        
        logger.info(f"üé§ TTS request for room {request.room_name}: '{request.text[:50]}...' (speaker: {speaker_id})")
        
        # Generate audio stream
        audio_stream = engine.synthesize_sft(
            request.text,
            speaker_id,
            request.streaming
        )
        
        # Publish to LiveKit
        result = await publisher.publish_audio_stream(
            request.room_name,
            audio_stream,
            engine.sample_rate
        )
        
        duration_ms = (time.time() - start_time) * 1000
        
        logger.info(f"‚úÖ Synthesis complete: {duration_ms:.0f}ms")
        
        return TTSResponse(
            status="completed",
            message="TTS synthesis successful",
            room_name=request.room_name,
            duration_ms=duration_ms,
            chunks_sent=result["chunks_sent"],
            mode=request.mode,
            text_length=len(request.text)
        )
        
    except Exception as e:
        debug_logger.error(f"‚ùå Synthesis failed: {e}")
        debug_logger.error(f"Traceback: {traceback.format_exc()}")
        
        # Return error response instead of raising exception
        return TTSResponse(
            status="error",
            message=f"Synthesis failed: {str(e)}",
            room_name=request.room_name,
            text_length=len(request.text)
        )

@app.post("/synthesize")
async def synthesize_simple(request: Request):
    """Simple synthesize endpoint (orchestrator fallback)"""
    debug_logger.info("üé§ SIMPLE SYNTHESIZE ENDPOINT")
    
    try:
        json_data = await request.json()
        debug_logger.info(f"Simple request: {json_data}")
        
        # Convert to our flexible format
        tts_request = FlexibleTTSRequest(
            text=json_data.get('text', ''),
            room_name=json_data.get('room_name', 'ozzu-main'),
            mode=json_data.get('mode', 'sft'),
            voice=json_data.get('voice'),
            speaker=json_data.get('speaker'),
            speaker_id=json_data.get('speaker_id')
        )
        
        # Use the advanced endpoint
        response = await synthesize_tts_advanced(tts_request)
        
        # Return simple format
        return {
            "status": "success" if response.status == "completed" else "error",
            "message": response.message or "TTS synthesis completed",
            "text_length": len(tts_request.text),
            "voice": tts_request.get_speaker_id(),
            "duration_ms": response.duration_ms
        }
        
    except Exception as e:
        debug_logger.error(f"‚ùå Simple synthesize error: {e}")
        return {
            "status": "error",
            "message": f"Synthesis failed: {str(e)}",
            "error": str(e)
        }

@app.get("/health")
@app.get("/healthz")
async def health_check():
    """Comprehensive health check"""
    debug_logger.info("üíö HEALTH CHECK")
    
    return HealthResponse(
        status="healthy",
        engine="cosyvoice2" if not engine or not engine.use_mock else "mock",
        model=config.cosyvoice.model_name,
        device=config.cosyvoice.device,
        gpu_available=torch.cuda.is_available(),
        streaming_enabled=config.cosyvoice.streaming,
        livekit_connected=publisher.connected if publisher else False,
        cosyvoice_available=COSYVOICE_AVAILABLE,
        livekit_available=LIVEKIT_AVAILABLE
    )

@app.get("/speakers")
async def list_speakers():
    """List available speakers"""
    debug_logger.info("üéµ SPEAKERS REQUEST")
    
    if not engine:
        return {"speakers": ["Ëã±ÊñáÂ•≥", "Ëã±ÊñáÁî∑", "‰∏≠ÊñáÂ•≥", "‰∏≠ÊñáÁî∑"]}
    
    speakers = engine.get_available_speakers()
    return {"speakers": speakers}

@app.get("/metrics")
async def get_metrics():
    """Service metrics"""
    gpu_info = {}
    if torch.cuda.is_available():
        try:
            gpu_info = {
                "gpu_memory_used_gb": torch.cuda.memory_allocated() / 1024**3,
                "gpu_memory_total_gb": torch.cuda.get_device_properties(0).total_memory / 1024**3,
                "gpu_name": torch.cuda.get_device_name(0)
            }
        except:
            pass
    
    return {
        "service": "tts",
        "status": "healthy",
        "engine": "mock" if (engine and engine.use_mock) else "cosyvoice2",
        "livekit_connected": publisher.connected if publisher else False,
        "debug_mode": True,
        **gpu_info
    }

@app.get("/")
async def root():
    """Service info"""
    debug_logger.info("üè† ROOT REQUEST")
    
    return {
        "service": "cosyvoice2-tts",
        "version": "1.0.0-fixed",
        "status": "healthy",
        "engine": "mock" if (engine and engine.use_mock) else "cosyvoice2",
        "features": [
            "sft_synthesis",
            "streaming",
            "robust_error_handling",
            "orchestrator_compatible",
            "mock_fallback",
            "comprehensive_debugging"
        ]
    }

# =============================================================================
# MAIN ENTRY POINT
# =============================================================================

if __name__ == "__main__":
    debug_logger.info("üî• STARTING ROBUST TTS SERVICE WITH UVICORN")
    
    uvicorn.run(
        "main_fixed:app",
        host=config.service.host,
        port=config.service.port,
        log_level="debug",
        access_log=True,
        reload=False
    )