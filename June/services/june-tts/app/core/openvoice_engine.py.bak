import asyncio
import base64
import glob
import inspect
import os
import tempfile
from typing import Optional, Tuple, Callable, Dict, Any, Union

import httpx
import numpy as np
import soundfile as sf


def _ensure_nltk() -> None:
    try:
        import nltk
        needed = ("averaged_perceptron_tagger_eng", "cmudict")
        for res in needed:
            try:
                if res.endswith("_eng"):
                    nltk.data.find(f"taggers/{res}/")
                else:
                    nltk.data.find(f"corpora/{res}")
            except LookupError:
                nltk.download(res, quiet=True, raise_on_error=True)
    except Exception:
        pass


_MAX_REF_BYTES = int(os.getenv("MAX_FILE_SIZE", str(20 * 1024 * 1024)))
_MAX_TEXT_LEN = int(os.getenv("MAX_TEXT_LEN", "2000"))
_SUPPORTED_LANGUAGES = {"en", "es", "fr", "zh", "ja", "ko"}

_MELO = None                   # type: ignore
_CONVERTER = None              # type: ignore
_SPEAKER_ID = None             # type: ignore
_CONVERT_FN: Optional[Callable[..., np.ndarray]] = None


def _env(name: str, default: Optional[str] = None) -> str:
    val = os.getenv(name, default or "")
    if not val:
        raise RuntimeError(f"{name} is required")
    return val


def _melo_language(language: str) -> str:
    lang_map = {"en": "EN", "es": "ES", "fr": "FR", "zh": "ZH", "ja": "JA", "ko": "KO"}
    return lang_map.get(language, os.getenv("MELO_LANGUAGE", "EN"))


def _ensure_checkpoints() -> Tuple[str, str, str]:
    root = _env("OPENVOICE_CHECKPOINTS_V2")
    base_root = os.path.join(root, "base_speakers")
    conv_root = os.path.join(root, "tone_color_converter")
    if not os.path.isdir(base_root):
        raise RuntimeError(f"Missing MeloTTS base_speakers at {base_root}")
    if not os.path.isdir(conv_root):
        raise RuntimeError(f"Missing tone_color_converter at {conv_root}")
    return root, base_root, conv_root


def _find_converter_ckpt(conv_root: str) -> str:
    for pattern in ("*.pth", "**/*.pth", "*.pt", "**/*.pt"):
        matches = glob.glob(os.path.join(conv_root, pattern), recursive=True)
        if matches:
            return matches[0]
    raise RuntimeError(f"No converter checkpoint (*.pth|*.pt) found under {conv_root}")


async def _download_reference(url: str) -> str:
    limits = httpx.Limits(max_connections=10, max_keepalive_connections=5)
    timeout = httpx.Timeout(30.0)
    async with httpx.AsyncClient(limits=limits, timeout=timeout, follow_redirects=True) as client:
        r = await client.get(url)
        r.raise_for_status()
        if len(r.content) > _MAX_REF_BYTES:
            raise ValueError("reference_url file too large")
        fd, path = tempfile.mkstemp(prefix="ov2-ref-", suffix=".bin")
        os.close(fd)
        with open(path, "wb") as f:
            f.write(r.content)
        return path


async def _write_reference_b64(b64: str) -> str:
    raw = base64.b64decode(b64)
    if len(raw) > _MAX_REF_BYTES:
        raise ValueError("reference_b64 too large")
    fd, path = tempfile.mkstemp(prefix="ov2-ref-", suffix=".bin")
    os.close(fd)
    with open(path, "wb") as f:
        f.write(raw)
    return path


def _coerce_speaker_id(spk: Union[int, str], melo: Any = None) -> int:
    try:
        return int(spk)
    except Exception:
        pass
    if isinstance(spk, str) and melo is not None:
        mp = getattr(melo, "spk2id", None)
        if isinstance(mp, dict) and spk in mp:
            try:
                return int(mp[spk])
            except Exception:
                pass
        hps = getattr(melo, "hps", None)
        data = getattr(hps, "data", None) if hps else None
        mp = getattr(data, "spk2id", None) if data else None
        if isinstance(mp, dict):
            key = spk.lower().replace("-", "_")
            for k, v in mp.items():
                if k.lower().replace("-", "_") == key:
                    try:
                        return int(v)
                    except Exception:
                        pass
    return 0


def _load_models_once() -> None:
    _ensure_nltk()

    global _MELO, _CONVERTER, _SPEAKER_ID, _CONVERT_FN
    if _MELO is not None and _CONVERTER is not None and _CONVERT_FN is not None:
        return

    try:
        from melo.api import TTS as MeloTTS          # type: ignore
        from openvoice.api import ToneColorConverter # type: ignore
        from openvoice import se_extractor           # noqa: F401
    except Exception as e:
        raise RuntimeError(
            "OpenVoice V2 runtime not installed. "
            "Install MeloTTS/OpenVoice and ensure checkpoints_v2 are present. "
            f"Import error: {e}"
        )

    _, _, conv_root = _ensure_checkpoints()
    ckpt = _find_converter_ckpt(conv_root)

    _MELO = MeloTTS(language=os.getenv("MELO_LANGUAGE", "EN"))
    _SPEAKER_ID = os.getenv("MELO_SPEAKER_ID", "0")

    cfg_path = os.path.join(conv_root, "config.json")
    device = os.getenv("OPENVOICE_DEVICE", "cuda" if os.getenv("CUDA_VISIBLE_DEVICES", "") != "" else "cpu")
    converter = ToneColorConverter(config_path=cfg_path, device=device)  # type: ignore[call-arg]
    if hasattr(converter, "load_ckpt"):
        converter.load_ckpt(ckpt)
    elif hasattr(converter, "load"):
        converter.load(ckpt_path=ckpt)
    else:
        raise RuntimeError("Unsupported ToneColorConverter: missing load/load_ckpt")

    
    def _convert_any(a: np.ndarray, sample_rate: int, src_se: np.ndarray) -> np.ndarray:
        """Try ndarray signatures first, then comprehensive path-based signatures (some write to file)."""
        a = a.astype(np.float32)

        # ---- ndarray signatures (newer builds) ----
        try:
            if hasattr(converter, "convert"):
                try:
                    return converter.convert(a, sample_rate, src_se)  # type: ignore[misc]
                except TypeError:
                    try:
                        return converter.convert(a, src_se, sample_rate)  # type: ignore[misc]
                    except TypeError:
                        pass
            if hasattr(converter, "tone_color_convert"):
                try:
                    return converter.tone_color_convert(a, sample_rate, src_se)  # type: ignore[attr-defined]
                except TypeError:
                    pass
        except Exception as e:
            # fall through to path-based
            pass

        # ---- path-based signatures (older builds expect an audio file path) ----
        import tempfile, os
        fd_in, tmp_in = tempfile.mkstemp(prefix="ov2-in-", suffix=".wav")
        os.close(fd_in)
        fd_out, tmp_out = tempfile.mkstemp(prefix="ov2-out-", suffix=".wav")
        os.close(fd_out)
        try:
            import soundfile as sf
            sf.write(tmp_in, a, sample_rate)

            attempts = []

            # convert(...positional...)
            attempts += [
                ((), dict(audio_src_path=tmp_in)),  # kwargs only
                ((tmp_in,), {}),                         # path only
                ((tmp_in, src_se), {}),                  # path, se
                ((tmp_in, src_se, sample_rate), {}),     # path, se, sr
            ]

            # convert(..., out_path/save_path/output_path=...)
            for key in ("out_path", "save_path", "output_path"):
                attempts += [
                    ((), {"audio_src_path": tmp_in, key: tmp_out}),
                    ((tmp_in,), {key: tmp_out}),
                    ((tmp_in, src_se), {key: tmp_out}),
                    ((tmp_in, src_se, sample_rate), {key: tmp_out}),
                    ((tmp_in,), {"src_se": src_se, key: tmp_out}),
                    ((), {"audio_src_path": tmp_in, "src_se": src_se, key: tmp_out}),
                    ((), {"audio_src_path": tmp_in, "src_se": src_se, "sample_rate": sample_rate, key: tmp_out}),
                ]

            # Also try tone_color_convert with path
            def _maybe_return_from_file():
                try:
                    import soundfile as sf, os
                    if os.path.exists(tmp_out) and os.path.getsize(tmp_out) > 44:  # header size-ish
                        data, sr2 = sf.read(tmp_out, dtype="float32")
                        return np.asarray(data, dtype=np.float32)
                except Exception:
                    pass
                return None

            # Try convert()
            if hasattr(converter, "convert"):
                for args, kwargs in attempts:
                    try:
                        out = converter.convert(*args, **kwargs)  # type: ignore[misc]
                        # Returned ndarray?
                        if isinstance(out, np.ndarray):
                            return out.astype(np.float32)
                        # Some builds return None but wrote to file
                        maybe = _maybe_return_from_file()
                        if maybe is not None:
                            return maybe
                    except TypeError:
                        continue
                    except Exception:
                        continue

            # Try tone_color_convert() with path variants
            if hasattr(converter, "tone_color_convert"):
                tone_attempts = [
                    ((tmp_in, sample_rate, src_se), {}),
                    ((tmp_in, src_se, sample_rate), {}),
                ]
                for args, kwargs in tone_attempts:
                    try:
                        out = converter.tone_color_convert(*args, **kwargs)  # type: ignore[misc]
                        if isinstance(out, np.ndarray):
                            return out.astype(np.float32)
                        maybe = _maybe_return_from_file()
                        if maybe is not None:
                            return maybe
                    except TypeError:
                        continue
                    except Exception:
                        continue

        finally:
            try:
                os.remove(tmp_in)
            except Exception:
                pass
            try:
                # don't remove tmp_out if we successfully returned its contents
                if Path(tmp_out).exists():
                    os.remove(tmp_out)
            except Exception:
                pass

        raise TypeError("No compatible ToneColorConverter.convert/tone_color_convert signature (ndarray or path) matched on this build")

    # Always prefer path-first convert (most OpenVoice V2 builds expect a file path)
    def _do_convert(audio, sample_rate, src_se):
        import tempfile, os, numpy as _np, soundfile as _sf
        # 1) write base audio to a temp wav (float32)
        fd, a_path = tempfile.mkstemp(prefix="ov2-base-", suffix=".wav")
        os.close(fd)
        _sf.write(a_path, _np.asarray(audio, dtype=_np.float32), int(sample_rate))
        try:
            # 2) try the common signatures of convert()
            try:
                # OpenVoice v2: convert(audio_src_path, src_se, sample_rate)
                return converter.convert(a_path, src_se, int(sample_rate))
            except TypeError:
                try:
                    # Alt order: convert(audio_src_path, sample_rate, src_se)
                    return converter.convert(a_path, int(sample_rate), src_se)
                except TypeError as e1:
                    # Some builds only expose tone_color_convert for ndarray
                    if hasattr(converter, "tone_color_convert"):
                        return converter.tone_color_convert(_np.asarray(audio, dtype=_np.float32), int(sample_rate), src_se)
                    raise e1
        finally:
            try: os.remove(a_path)
            except Exception: pass

    _CONVERT_FN = _do_convert
    _CONVERTER = converter
    _CONVERT_FN = _convert_any


def warmup_models() -> None:
    _load_models_once()


def _maybe_add_language_kw(fn: Callable[..., Any], kwargs: Dict[str, Any], language: str) -> None:
    try:
        sig = inspect.signature(fn)
        if "language" in sig.parameters:
            kwargs["language"] = language
    except Exception:
        pass


def _filter_kwargs_for(fn: Callable[..., Any], kwargs: Dict[str, Any]) -> Dict[str, Any]:
    try:
        sig = inspect.signature(fn)
        if any(p.kind == inspect.Parameter.VAR_KEYWORD for p in sig.parameters.values()):
            return kwargs
        allowed = set(sig.parameters.keys())
        return {k: v for k, v in kwargs.items() if k in allowed}
    except Exception:
        allow = {"text", "speaker_id", "speed", "language", "output_path"}
        return {k: v for k, v in kwargs.items() if k in allow}


def _resolve_melo_audio(
    *,
    tts_obj: Any,
    melo_lang: str,
    text: str,
    speaker_id: Union[int, str],
    speed: float,
    volume: float,
    pitch: float,
) -> Tuple[np.ndarray, int]:
    spk_idx = _coerce_speaker_id(speaker_id, tts_obj)
    kwargs: Dict[str, Any] = dict(text=text, speaker_id=spk_idx, speed=float(speed), volume=float(volume), pitch=float(pitch))

    if hasattr(tts_obj, "tts_to_audio"):
        fn = tts_obj.tts_to_audio
        _maybe_add_language_kw(fn, kwargs, melo_lang)
        out = fn(**_filter_kwargs_for(fn, kwargs))
        if isinstance(out, tuple) and len(out) == 2:
            audio, sr = out  # type: ignore[misc]
        else:
            audio = out  # type: ignore[assignment]
            sr = getattr(tts_obj, "sample_rate", None) or getattr(tts_obj, "sr", None) or 22050
        return np.asarray(audio, dtype=np.float32), int(sr)

    if hasattr(tts_obj, "tts_to_file"):
        fn = tts_obj.tts_to_file
        _maybe_add_language_kw(fn, kwargs, melo_lang)
        fd, tmpwav = tempfile.mkstemp(prefix="melo-out-", suffix=".wav")
        os.close(fd)
        try:
            fn(output_path=tmpwav, **_filter_kwargs_for(fn, kwargs))
            data, sr = sf.read(tmpwav, dtype="float32")
            return np.asarray(data, dtype=np.float32), int(sr)
        finally:
            try:
                os.remove(tmpwav)
            except Exception:
                pass

    if hasattr(tts_obj, "tts"):
        fn = tts_obj.tts
        _maybe_add_language_kw(fn, kwargs, melo_lang)
        audio = fn(**_filter_kwargs_for(fn, kwargs))
        sr = getattr(tts_obj, "sample_rate", None) or getattr(tts_obj, "sr", None) or 22050
        return np.asarray(audio, dtype=np.float32), int(sr)

    raise RuntimeError("Unsupported MeloTTS build: no tts_to_audio/tts_to_file/tts")


async def synthesize_v2_to_wav_path(
    *,
    text: str,
    language: str,
    reference_b64: Optional[str],
    reference_url: Optional[str],
    speed: float,
    volume: float,
    pitch: float,
    metadata: dict,
) -> str:
    if not text:
        raise ValueError("text is required")
    if len(text) > _MAX_TEXT_LEN:
        raise ValueError("text too long")
    lang = language.lower()
    if lang not in _SUPPORTED_LANGUAGES:
        raise ValueError(f"language must be one of {_SUPPORTED_LANGUAGES}")
    if speed <= 0:
        raise ValueError("speed must be > 0")

    _load_models_once()
    assert _MELO is not None and _CONVERTER is not None and _CONVERT_FN is not None

    ref_path: Optional[str] = None
    if reference_b64:
        ref_path = await _write_reference_b64(reference_b64)
    elif reference_url:
        ref_path = await _download_reference(reference_url)
    if not ref_path:
        raise ValueError("reference audio not provided")

    melo_lang = _melo_language(lang)
    spk = _SPEAKER_ID or "0"
    base_audio, sr = _resolve_melo_audio(
        tts_obj=_MELO, melo_lang=melo_lang, text=text, speaker_id=spk, speed=speed, volume=volume, pitch=pitch
    )

    from openvoice import se_extractor
    try:
        src_se, _ = se_extractor.get_se(ref_path, _CONVERTER, vad=True)  # type: ignore[arg-type]
    except TypeError:
        src_se = se_extractor.get_se(ref_path)

    converted_audio = _CONVERT_FN(base_audio, sr, src_se)

    fd, out_path = tempfile.mkstemp(prefix="june-tts-v2-", suffix=".wav")
    os.close(fd)
    sf.write(out_path, converted_audio, sr, subtype="PCM_16")

    async def _cleanup():
        try:
            if os.path.exists(ref_path):
                os.remove(ref_path)
        except Exception:
            pass

    asyncio.create_task(_cleanup())
    return out_path
