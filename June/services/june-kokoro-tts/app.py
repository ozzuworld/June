# services/june-kokoro-tts/app.py
import os
import io
import time
import logging
import asyncio
from typing import Optional, Dict, Any
import tempfile
import subprocess

from fastapi import FastAPI, Query, Depends, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse, JSONResponse
import torch
import torchaudio
import soundfile as sf
import numpy as np

# Import auth modules
from shared.auth_service import require_service_auth

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="June Kokoro TTS", version="1.0.0")

# Global variables for model
kokoro_pipeline = None
available_voices = {}

class KokoroTTSEngine:
    """Kokoro TTS Engine with CPU optimization"""
    
    def __init__(self, model_path: str = "/app/models"):
        self.model_path = model_path
        self.device = "cpu"  # Force CPU for reliability
        self.pipeline = None
        self.voices = {}
        self.sample_rate = 24000
        
    async def initialize(self):
        """Initialize the Kokoro model"""
        try:
            logger.info("üöÄ Initializing Kokoro TTS...")
            
            # Try importing kokoro
            try:
                from kokoro import KPipeline
                logger.info("‚úÖ Kokoro library imported successfully")
            except ImportError as e:
                logger.error(f"‚ùå Failed to import Kokoro: {e}")
                # Fallback to manual implementation
                return await self._initialize_manual()
            
            # Initialize pipeline with American English
            self.pipeline = KPipeline(lang_code='a')  # 'a' for American English
            
            # Load available voices
            self.voices = {
                'af_bella': 'American Female - Bella',
                'af_nicole': 'American Female - Nicole', 
                'af_sarah': 'American Female - Sarah',
                'af_sky': 'American Female - Sky',
                'am_adam': 'American Male - Adam',
                'am_michael': 'American Male - Michael'
            }
            
            logger.info(f"‚úÖ Kokoro TTS initialized with {len(self.voices)} voices")
            logger.info(f"üì± Available voices: {list(self.voices.keys())}")
            
            # Test synthesis
            await self._test_synthesis()
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Kokoro TTS: {e}")
            return False
    
    async def _initialize_manual(self):
        """Manual initialization if kokoro package fails"""
        logger.warning("‚ö†Ô∏è Using manual Kokoro implementation")
        
        # Check if model files exist
        model_files = [
            "pytorch_model.bin",
            "config.json", 
            "voices.bin"
        ]
        
        missing_files = []
        for file in model_files:
            if not os.path.exists(os.path.join(self.model_path, file)):
                missing_files.append(file)
        
        if missing_files:
            logger.error(f"‚ùå Missing model files: {missing_files}")
            return False
        
        # Simple voice mapping for manual mode
        self.voices = {
            'af_bella': 'American Female - Bella (Manual)',
            'cpu_voice': 'CPU Optimized Voice'
        }
        
        logger.info("‚úÖ Manual Kokoro mode initialized")
        return True
    
    async def _test_synthesis(self):
        """Test synthesis to ensure everything works"""
        try:
            test_text = "Hello, this is a test of Kokoro TTS."
            audio_data = await self.synthesize(test_text, voice="af_bella")
            
            if audio_data and len(audio_data) > 1000:
                logger.info("‚úÖ Synthesis test passed")
            else:
                logger.warning("‚ö†Ô∏è Synthesis test produced short audio")
                
        except Exception as e:
            logger.error(f"‚ùå Synthesis test failed: {e}")
    
    async def synthesize(
        self,
        text: str,
        voice: str = "af_bella",
        speed: float = 1.0,
        output_format: str = "wav"
    ) -> Optional[bytes]:
        """Synthesize speech from text"""
        try:
            logger.info(f"üéµ Synthesizing: '{text[:50]}...' with voice '{voice}'")
            
            if not self.pipeline:
                # Use manual synthesis
                return await self._manual_synthesize(text, voice, speed, output_format)
            
            # Use Kokoro pipeline
            generator = self.pipeline(text, voice=voice)
            
            # Collect all audio chunks
            audio_chunks = []
            for i, (gs, ps, audio) in enumerate(generator):
                if audio is not None and len(audio) > 0:
                    audio_chunks.append(audio)
                    
                # Limit to prevent infinite loops
                if i > 100:
                    break
            
            if not audio_chunks:
                logger.error("‚ùå No audio generated")
                return None
            
            # Concatenate audio chunks
            full_audio = np.concatenate(audio_chunks)
            
            # Apply speed adjustment
            if speed != 1.0:
                full_audio = self._adjust_speed(full_audio, speed)
            
            # Convert to output format
            return await self._convert_audio(full_audio, output_format)
            
        except Exception as e:
            logger.error(f"‚ùå Synthesis failed: {e}")
            return await self._fallback_synthesis(text, output_format)
    
    async def _manual_synthesize(
        self,
        text: str,
        voice: str,
        speed: float,
        output_format: str
    ) -> Optional[bytes]:
        """Manual synthesis using eSpeak-NG as fallback"""
        try:
            logger.info("üîß Using eSpeak-NG fallback synthesis")
            
            # Use eSpeak-NG with better voice settings
            espeak_cmd = [
                "espeak-ng",
                "-v", "en+f3",  # Female voice variant
                "-s", str(int(150 * speed)),  # Speed (words per minute)
                "-a", "100",  # Amplitude
                "-g", "5",    # Gap between words
                "--stdout",
                text
            ]
            
            # Run eSpeak-NG
            result = subprocess.run(
                espeak_cmd,
                capture_output=True,
                check=True
            )
            
            audio_data = result.stdout
            
            if output_format.lower() == "mp3":
                # Convert WAV to MP3 using ffmpeg
                return await self._convert_wav_to_mp3(audio_data)
            
            return audio_data
            
        except Exception as e:
            logger.error(f"‚ùå Manual synthesis failed: {e}")
            return None
    
    async def _fallback_synthesis(self, text: str, output_format: str) -> Optional[bytes]:
        """Ultra-simple fallback using eSpeak-NG"""
        try:
            logger.warning("‚ö†Ô∏è Using ultra-simple fallback")
            
            cmd = ["espeak-ng", "--stdout", text]
            result = subprocess.run(cmd, capture_output=True, check=True)
            
            return result.stdout
            
        except Exception as e:
            logger.error(f"‚ùå Fallback synthesis failed: {e}")
            return None
    
    def _adjust_speed(self, audio: np.ndarray, speed: float) -> np.ndarray:
        """Adjust audio speed"""
        if speed == 1.0:
            return audio
        
        try:
            # Simple speed adjustment by resampling
            from scipy import signal
            new_length = int(len(audio) / speed)
            return signal.resample(audio, new_length)
        except Exception:
            logger.warning("‚ö†Ô∏è Speed adjustment failed, using original audio")
            return audio
    
    async def _convert_audio(self, audio: np.ndarray, output_format: str) -> bytes:
        """Convert audio to requested format"""
        try:
            with tempfile.NamedTemporaryFile(suffix=f".{output_format}") as temp_file:
                if output_format.lower() == "wav":
                    sf.write(temp_file.name, audio, self.sample_rate)
                elif output_format.lower() == "mp3":
                    # Save as WAV first, then convert
                    wav_file = temp_file.name.replace(".mp3", ".wav")
                    sf.write(wav_file, audio, self.sample_rate)
                    await self._convert_wav_to_mp3_file(wav_file, temp_file.name)
                
                temp_file.seek(0)
                return temp_file.read()
                
        except Exception as e:
            logger.error(f"‚ùå Audio conversion failed: {e}")
            # Return raw audio as bytes
            return audio.astype(np.float32).tobytes()
    
    async def _convert_wav_to_mp3(self, wav_data: bytes) -> bytes:
        """Convert WAV data to MP3"""
        try:
            with tempfile.NamedTemporaryFile(suffix=".wav") as wav_file:
                with tempfile.NamedTemporaryFile(suffix=".mp3") as mp3_file:
                    wav_file.write(wav_data)
                    wav_file.flush()
                    
                    # Use ffmpeg to convert
                    cmd = [
                        "ffmpeg", "-i", wav_file.name,
                        "-acodec", "mp3", "-ab", "128k",
                        "-y", mp3_file.name
                    ]
                    
                    subprocess.run(cmd, capture_output=True, check=True)
                    
                    mp3_file.seek(0)
                    return mp3_file.read()
                    
        except Exception as e:
            logger.error(f"‚ùå WAV to MP3 conversion failed: {e}")
            return wav_data  # Return original if conversion fails
    
    async def _convert_wav_to_mp3_file(self, wav_path: str, mp3_path: str):
        """Convert WAV file to MP3 file"""
        cmd = [
            "ffmpeg", "-i", wav_path,
            "-acodec", "mp3", "-ab", "128k", 
            "-y", mp3_path
        ]
        subprocess.run(cmd, capture_output=True, check=True)

# Initialize the TTS engine
@app.on_event("startup")
async def startup_event():
    """Initialize TTS engine on startup"""
    global kokoro_pipeline, available_voices
    
    logger.info("üöÄ Starting Kokoro TTS service...")
    
    kokoro_pipeline = KokoroTTSEngine()
    success = await kokoro_pipeline.initialize()
    
    if success:
        available_voices = kokoro_pipeline.voices
        logger.info("‚úÖ Kokoro TTS service ready")
    else:
        logger.error("‚ùå Failed to initialize Kokoro TTS")
        available_voices = {"fallback": "eSpeak-NG Fallback"}

# Health check endpoint
@app.get("/healthz")
async def healthz():
    """Health check endpoint"""
    return {
        "ok": True,
        "service": "june-kokoro-tts",
        "timestamp": time.time(),
        "status": "healthy",
        "engine": "kokoro" if kokoro_pipeline and kokoro_pipeline.pipeline else "espeak-fallback",
        "voices_available": len(available_voices)
    }

@app.get("/")
async def root():
    """Root endpoint"""
    return {
        "service": "june-kokoro-tts",
        "status": "running",
        "engine": "kokoro-cpu-optimized",
        "voices": list(available_voices.keys())
    }

@app.get("/v1/voices")
async def list_voices():
    """List available voices"""
    return {
        "voices": available_voices,
        "default": "af_bella",
        "engine": "kokoro"
    }

# Service-to-Service TTS Endpoint
@app.post("/v1/tts")
async def synthesize_speech_service(
    text: str = Query(..., description="Text to synthesize"),
    voice: str = Query("af_bella", description="Voice to use"),
    speed: float = Query(1.0, description="Speech speed (0.5-2.0)"),
    audio_encoding: str = Query("MP3", description="Audio format: MP3 or WAV"),
    service_auth_data: dict = Depends(require_service_auth)
):
    """
    TTS endpoint for service-to-service communication
    Protected by service authentication
    """
    calling_service = service_auth_data.get("client_id", "unknown")
    
    try:
        # Validate input
        if len(text) > 5000:
            raise HTTPException(status_code=400, detail="Text too long (max 5000 characters)")
        
        if speed < 0.5 or speed > 2.0:
            raise HTTPException(status_code=400, detail="Speed must be between 0.5 and 2.0")
        
        if voice not in available_voices and voice != "default":
            logger.warning(f"Voice '{voice}' not available, using default")
            voice = "af_bella"
        
        logger.info(f"üéµ TTS request from {calling_service}: '{text[:100]}...' ({len(text)} chars)")
        
        # Synthesize speech
        audio_data = await kokoro_pipeline.synthesize(
            text=text,
            voice=voice,
            speed=speed,
            output_format=audio_encoding.lower()
        )
        
        if not audio_data:
            raise HTTPException(status_code=500, detail="Speech synthesis failed")
        
        # Determine media type
        if audio_encoding.upper() == "MP3":
            media_type = "audio/mpeg"
            ext = "mp3"
        else:
            media_type = "audio/wav" 
            ext = "wav"
        
        logger.info(f"‚úÖ TTS successful: {len(audio_data)} bytes generated for {calling_service}")
        
        return StreamingResponse(
            io.BytesIO(audio_data),
            media_type=media_type,
            headers={
                "Content-Disposition": f"attachment; filename=speech.{ext}",
                "X-Processed-By": "june-kokoro-tts",
                "X-Caller-Service": calling_service,
                "X-Voice-Used": voice,
                "X-Engine": "kokoro-cpu"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå TTS synthesis failed: {e}")
        raise HTTPException(status_code=500, detail=f"TTS synthesis failed: {str(e)}")

# Test endpoint (for debugging)
@app.get("/v1/test")
async def test_synthesis(
    text: str = Query("Hello, this is a test of Kokoro TTS running on CPU."),
    voice: str = Query("af_bella")
):
    """Test endpoint for direct synthesis testing"""
    try:
        audio_data = await kokoro_pipeline.synthesize(text, voice)
        
        if audio_data:
            return StreamingResponse(
                io.BytesIO(audio_data),
                media_type="audio/wav",
                headers={"X-Test": "kokoro-tts"}
            )
        else:
            return JSONResponse(
                status_code=500,
                content={"error": "Synthesis failed", "text": text}
            )
            
    except Exception as e:
        logger.error(f"Test synthesis failed: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e), "text": text}
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8080, reload=True)